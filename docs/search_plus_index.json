{"./":{"url":"./","title":"前言","keywords":"","body":"黎明的奔跑 求知若渴,虚心若愚 Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-28 13:10:57 "},"linux/redis.html":{"url":"linux/redis.html","title":"搭建redis","keywords":"","body":"redis redis概述 1.1 redis介绍 redis是NoSQL中的一种，基于键-值型的存储，与memcache类似，但是memcache中只是内存的缓存，而redis不仅是内存中的缓存，还提供持久存储，在2009年第一次发布redis Redis 全称（REmote DIctionary Server）远程字典服务器，而这个字典服务器从本质上来讲，主要是提供数据结构的远程存储功能的，可以理解为redis是一个高级的K-V存储，和数据结构存储，因为redis除了能够存储K-V这种简单的数据之外，还能够存储，列表、字典、hash表、等对应的数据结构 redis与mamcache不同之处在于redis有一个周期性的将数据保存到磁盘上的机制，而且不只一种，有两种机制，这也是redis持久化的一种实现，另外与mamcache有所区别的是，redis是单线程服务器，只有一个线程来响应所有的请求 redis支持主从模式，但是redis的主从模式默认就有一个sentinel工具，从而实现主从架构的高可用，也就是说，redis能够借助于sentinel工具来监控主从节点，当主节点发生故障时，会自己提升另外一个从节点成为新的主节点 在redis 3.0版本发布，开始支持redis集群，从而可以实现分布式，可以将用户的请求分散至多个不同节点 redis支持的数据类型 支持存储的数据类型有、String（字符串，包含整数）, List（列表）, Hash（关联数组）, Sets（集合）, Sorted Sets（有序集合）, Bitmaps（位图）, HyperLoglog redis性能评估 1、100万较小的键存储字符串，大概消耗100M内存 2、由于redis是单线程，如果服务器主机上有多个CPU，只有一个能够使用，但并不意味着CPU会成为瓶颈，因为redis是一个比较简单的K-V数据存储，CPU通常不会成为瓶颈的 3、在常见的linux服务器上，500K（50万）的并发，只需要一秒钟处理，如果主机硬件较好的情况下，每秒钟可以达到上百万的并发 1.4 redis与memcache对比 Memcache是一个分布式的内存对象缓存系统 而redis是可以实现持久存储 Memcache是一个LRU的缓存 redis支持更多的数据类型 Memcache是多线程的 redis是单线程的 二者性能几乎不相上下，实际上redis会受到硬盘持久化的影响，但是性能仍然保持在与Memcache不相上下 redis优势 1.丰富的（资料形态）操作，String（字符串，包含整数）, List（列表）, Hash（关联数组）,Sets（集合）, Sorted Sets（有序集合）, Bitmaps（位图）, HyperLoglog 2.内建Replication和culster（自身支持复制及集群功能） 3.支持就地更新（in-place update）操作，直接可以在内存中完成更新操作 4.支持持久化（磁盘） 5.避免雪崩效应，万一出现雪崩效应，所有的数据都无法恢复，但redis由于有持久性的数据，可以实现恢复 1.6 memcache优势 多线程 善用多核CPU 更少的阻塞操作 更少的内存开销 更少的内存分配压力 可能有更少的内存碎片 安装redis 2.1 源码安装redis [root\\@lewis63 ~]# yum -y install gcc* [root\\@lewis63 ~]# tar zxf redis-4.0.10.tar.gz -C /usr/local/ [root\\@lewis63 ~]# cd /usr/local/redis-4.0.10/ [root\\@lewis63 redis-4.0.10]# make -j 2 && make install 默认前台启动，后台需修改配置文件或制作启动脚本 启动脚本： [root\\@lewis63 ~]# vim /usr/lib/systemd/system/redis.service [Unit] Description=Redis persistent key-value database After=network.target [Service] ExecStart=/usr/local/redis-4.0.10/src/redis-server /usr/local/redis-4.0.10/redis.conf --supervised systemd ExecStop=/usr/libexec/redis-shutdown Type=notify User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target [root\\@lewis63 ~]# useradd -r -s /sbin/nologin redis #添加redis用户 [root\\@lewis63 ~]# systemctl daemon-reload #重新加载Unit文件 [root\\@lewis63 ~]# systemctl start redis #启动redis [root\\@lewis63 ~]# netstat -anput | grep 6379 tcp 0 0 127.0.0.1:6379 0.0.0.0:* LISTEN 4737/redis-server 1 redis-shutdown停止脚本 [root\\@lewis63 ~]# vim /usr/libexec/redis-shutdown #!/bin/bash # # Wrapper to close properly redis and sentinel test x\"$REDIS_DEBUG\" != x && set -x REDIS_CLI=/usr/local/redis-4.0.10/src/redis-cli #需要修改为redis安装路径redis-cli位置 # Retrieve service name #!/bin/bash # # Wrapper to close properly redis and sentinel test x\"$REDIS_DEBUG\" != x && set -x REDIS_CLI=/usr/local/redis-4.0.10/src # Retrieve service name SERVICE_NAME=\"$1\" if [ -z \"$SERVICE_NAME\" ]; then SERVICE_NAME=redis fi # Get the proper config file based on service name CONFIG_FILE=\"/etc/$SERVICE_NAME.conf\" # Use awk to retrieve host, port from config file HOST=`awk '/\\^[[:blank:]]*bind/ { print $2 }' $CONFIG_FILE | tail -n1` PORT=`awk '/\\^[[:blank:]]*port/ { print $2 }' $CONFIG_FILE | tail -n1` PASS=`awk '/\\^[[:blank:]]*requirepass/ { print $2 }' $CONFIG_FILE | tail -n1` SOCK=`awk '/\\^[[:blank:]]*unixsocket\\s/ { print $2 }' $CONFIG_FILE | tail -n1` # Just in case, use default host, port HOST=${HOST:-127.0.0.1} if [ \"$SERVICE_NAME\" = redis ]; then PORT=${PORT:-6379} else PORT=${PORT:-26739} fi # Setup additional parameters # e.g password-protected redis instances [ -z \"$PASS\" ] || ADDITIONAL_PARAMS=\"-a $PASS\" # shutdown the service properly if [ -e \"$SOCK\" ] ; then $REDIS_CLI -s $SOCK $ADDITIONAL_PARAMS shutdown else $REDIS_CLI -h $HOST -p $PORT $ADDITIONAL_PARAMS shutdown [root\\@lewis63 libexec]# chmod +x redis-shutdown [root\\@lewis63 ~]# systemctl stop redis [root\\@lewis63 ~]# netstat -anput | grep 6379 2.2 使用RPM包安装redis yum -y localinstall redis-4.0.10-1.el7.remi.x86_64.rpm systemctl start redis 2.3配置环境变量 [root\\@lewis63 ~]# echo \"export PATH=$PATH:/usr/local/redis-4.0.10/src\" >> /etc/profile [root\\@lewis63 ~]# source /etc/profile [root\\@lewis63 ~]# redis-cli 127.0.0.1:6379> redis基本操作 3.1 redis配置文件 daemonize no //表示redis并不会运行成为一个守护进程，如果需要运行成为一个守护进程，则把no，改为yes即可，如果使用服务脚本启动，即使daemonize为no，也会运行为一个守护进程 port 6379 //监听端口：6379/tcp tcp-backlog 511 //指定tcp-backlog的长度 说明：任何的tcp服务都有可能使用到tcp-backlog功能，backlog是一个等待队列，比如：redis的并发很高时，redis有可以运行不过来时，就连接本地缓存等队列都满了以后，就会使用额外的存储地方，把新来的请求暂存下来，而这个位置则称为backlog bind 127.0.0.1 //监听的地址，默认监听在127.0.0.1地址上，可以指定为0.0.0.0地址，或某个特定的地址，或可以指定多个，使用空格分隔即可 # unixsocket /tmp/redis.sock //指定使用sock文件通信及sock文件位置，如果服务端和客户都在同一台主机上，建议打开此项，基于sock方式通信可以直接在内存中交换，数据不用再经过TCP/TP协议栈进行封装、拆封 # unixsocketperm 700 //定义sock文件的访问权限 timeout 0 //表示当客户端连接成功后，空闲（非活跃、或没有任何数据交互）多长时间则连接超时，0表示不启用此功能 tcp-keepalive 0 //定义是否启用tcp-keepalive功能 loglevel notice //定义日志级别 logfile /var/log/redis/redis.log //定义日志文件 databases 16 //定义redis默认有多少个databases，但是在分布式中，只能使用一个 #### SNAPSHOTTING #### //定义RDB的持久化相关 save \\ \\ //使用save指令，并指定每隔多少秒，如果发生多大变化，进行存储 示例： save 900 1 //表示在900秒（15分钟内），如果至少有1个键发生改变，则做一次快照（持久化） save 300 10 //表示在300秒（5分钟内），如果至少有10个键发生改变，则做一次快照（持久化） save 60 10000 //表示在60秒（1分钟内），如果至少有10000个键发生改变，则做一次快照（持久化） save \"\" //如果redis中的数据不需做持久化，只是作为缓存，则可以使用此方式关闭持久化功能 ######## REPLICATION ####### //配置主从相关 # slaveof \\ \\ //此项不启用时，则为主，如果启动则为从，但是需要指明主服务器的IP，端口 # masterauth \\ //如果主服务设置了密码认证，那么从的则需要启用此项并指明主的认证密码 slave-read-only yes //定义从服务对主服务是否为只读（仅复制） ##### LIMITS ##### //定义与连接和资源限制相关的配置 # maxclients 10000 //定义最大连接限制（并发数） # maxmemory \\ //定义使用主机上的最大内存，默认此项关闭，表示最大将使用主机上的最大可用内存 ###### APPEND ONLY MODE ####### //定义AOF的持久化功能相关配置，一旦有某一个键发生变化，将修改键的命令附加到命令列表的文件中，类似于MySQL二进制日志 appendonly no //定义是否开启此功能，no表示关闭，yes表示开启 说明：RDB和AOF两种持久功能可以同时启用，两者不影响 3.2 登录redis 前面已经设置了环境变量 [root\\@lewis63 ~]# redis-cli –h 选项： -h \\ 指定主机IP -p \\ 指定端口socket文件进行通信 -s \\ 指定socket文件，如果客户端口和服务端都在同一台主机，可以指定socket文件进行通信 -a \\ 指定认证密码 -r \\ 连接成功后指定运行的命令N次 -i \\ 连接成功后每个命令执行完成等待时间，使用-i选项指定 -n \\ [root\\@lewis63 ~]# redis-cli #使用redis-cli直接连接，默认连接是127.0.0.1 IP 127.0.0.1:6379> 或 [root\\@lewis63 ~]# vim /usr/local/redis-4.0.10/redis.conf bind 192.168.1.63 #修改绑定地址 [root\\@lewis63 ~]# systemctl start redis [root\\@lewis63 ~]# redis-cli -h 192.168.1.63 192.168.1.63:6379> 3.3 redis获取帮助 127.0.0.1:6379> help //获取使用帮助 说明：redis的help命令非常强大，因为redis支持众多的数据结构，每一种数据结构当中都支持N种操作，因此需要使用 help \\@group方式来获取某一种数据结构所支持的操作 例：获取字符串组所支持有那些操作 127.0.0.1:6379> help \\@string 127.0.0.1:6379> help APPEND //获取单个命令的使用方法 APPEND key value //命令方法 summary: Append a value to a key since: 2.0.0 //说明此命令在哪个版本中引入的 group: string //该命令所属哪一个组 查看都有哪些组： 127.0.0.1:6379> help TAB键，每敲一次轮换一个，带有\\@则为一个组，不带\\@则为命令使用 切换库（名称空间）： 127.0.0.1:6379> select 1 //表示切换到1号库中，默认为0号库，共16个，0-15 OK 127.0.0.1:6379[1]> 3.4 键的遵循 可以使用ASCII字符 键的长度不要过长，键的长度越长则消耗的空间越多 在同一个库中（名称空间），键的名称不得重复，如果复制键的名称，实际上是修改键中的值 在不同的库中（名称空间），键的名称可以重复 键可以实现自动过期 3.5 String的操作 127.0.0.1:6379> help set SET key value [EX seconds] [PX milliseconds] [NX|XX] //命令 键 值 [EX 过期时间，单位秒] summary: Set the string value of a key since: 1.0.0 group: string NX：如果一个键不存在，才创建并设定值，否则不允许设定 XX：如果一个键存在则设置建的值，如果不存在则不创建并不设置其值（更新） 例： 127.0.0.1:6379> set cjk lzll OK 127.0.0.1:6379> set cjk aaa NX (nil) //反回提示一个没能执行的操作 127.0.0.1:6379> get cjk \"lzll\" 127.0.0.1:6379> set foo abc XX (nil) 定义一个键并设置过期时间为60秒 127.0.0.1:6379> set fda abc EX 60 OK 获取键中的值： 127.0.0.1:6379> help get GET key summary: Get the value of a key since: 1.0.0 group: string 例： 127.0.0.1:6379> get cjk \"lzll\" 添加键中的值（在原有键中附加值的内容）： 127.0.0.1:6379> set cjk aaa OK 127.0.0.1:6379> append cjk bbb (integer) 6 127.0.0.1:6379> get cjk \"aaabbb\" 获取指定键中的值的字符串的长度： 127.0.0.1:6379> strlen cjk (integer) 6 定义整数值： 127.0.0.1:6379> set fda 1 OK 增加键中的整数值： 127.0.0.1:6379> incr fda (integer) 2 127.0.0.1:6379> incr fda (integer) 3 127.0.0.1:6379> incr fda (integer) 4 127.0.0.1:6379> incr fda (integer) 5 127.0.0.1:6379> get fda \"5\" 注：incr命令只能对整数使用 3.6 列表的操作 键指向一个列表，而列表可以理解为是一个字符串的容器，列表是有众多元素组成的集合，可以在键所指向的列表中附加一个值 Lists的常用命令: LPUSH //在键所指向的列表前面插入一个值（左边加入） RPUSH //在键所指向的列表后面附加一个值（右边加入） LPOP //在键所指向的列表前面弹出一个值（左边弹出） RPOP //在键所指向的列表后面弹出一个值（右边弹出） LINDEX //根据索引获取值，指明索引位置进行获取对应的值 LSET //用于修改指定索引的值为指定的值 例： 127.0.0.1:6379> help \\@list LSET key index value summary: Set the value of an element in a list by its index since: 1.0.0 指定一个新的列表，在帮助中并没产明哪个命令用于创建一个新的列表，实际上创建一个新的列表使用LPUSH或RPUSH都可以 例： 127.0.0.1:6379> lpush ll cjk //ll为列表名称，cjk为值（索引） (integer) 1 获取列表中的值：需要指明索引位置进行获取对应的值 127.0.0.1:6379> lindex ll 0 //第一个索引则为0 \"cjk\" 在原有的列表中的左侧加入一个值： 127.0.0.1:6379> lpush ll fda (integer) 2 127.0.0.1:6379> lindex ll 0 \"fda\" 127.0.0.1:6379> lindex ll 1 \"cjk\" 在原有的列表中的右侧加入一个值 127.0.0.1:6379> rpush ll lzz (integer) 3 127.0.0.1:6379> lindex ll 2 \"lzz\" 127.0.0.1:6379> lindex ll 1 \"cjk\" 3.7 密码认证 [root\\@lewis63 ~]# vim /usr/local/redis-4.0.10/redis.conf 改：# requirepass foobared 为：requirepass foo 测试： 127.0.0.1:6379> set a lss (error) NOAUTH Authentication required. 127.0.0.1:6379> auth foo #认证 OK 127.0.0.1:6379> set a kk OK 3.8 清空数据库 127.0.0.1:6379> FLUSHDB #删除当前选择的数据库所有key OK 127.0.0.1:6379> FLUSHALL #清空所有库 OK redis持久化 4.1 概述 默认情况下，redis工作时所有数据集都是存储于内存中的，不论是否有磁盘上的持久化数据，都是工作于内存当中，redis本身就是一个内存的数据库，把所有数据库相关的存储都存储在内存中，如果redis崩溃或断电导致所有数据丢失，所以redis提供了持久化功能来保证数据的可靠性，redis持久化有两种实现，RDB和AOF 4.2 持久化RDB RDB: 存储为二进制格式的数据文件，默认启动的持久化机制；按事先定制的策略，周期性地将数据保存至磁盘，使用save命令即可设定周期和策略即可；数据文件默认为dump.rdb，客户端连接服务器以后可以用去使用save命令进行保存数据至磁盘 保存快照有两种方式： 1、客户端也可显式使用SAVE或BGSAVE命令启动快照保存机制； 2、借助于配置文件所定义的save和策略进行保存 SAVE: 是同步保存，在客户端使用save保存快照时，是在redis主线程中保存快照；因为redis的主线程是用于处理请求的，所以此时会阻塞所有客户端请求，每次的保存快照都是把内存中的数据完整的保存一份，并非是增量的，如果内存中的数据比较大，而还有大量的写操作请求时，此方式会引起大量的I/O，会导致redis性能下降 BGSAVE：异步方式，将立即返回结果，但自动在后台保持操作，所以BGSAVE命令启动以后，前台不会被占用，客户端的的请求是不会被阻塞（主进程不会被阻塞） 如果是在配置文件中定义的save，那么redis在持久化的时候，则会开启另外的进程去处理，不会阻塞redis的主进程 redis的RDB持久化不足之处则是，一旦数据出现问题，由于RDB的数据不是最新的，所以基于RDB恢复过来的数据一定会有一部分数据丢失，也就是RDB保存之后的修改的数据会丢失 4.3 持久化AOF AOF：Append Only File，有着更好的持久化能力的解决方案，AOF类似于MySQL的二进制日志，记录每一次redis的写操作命令，以顺序IO方式附加在指定文件的尾部，是使用追加方式实现的，这也叫做一种附加日志类型的持久化机制，由于每一次的操作都记录，则会随着时间长而增大文件的容量，并且有些记录的命令是多余的，AOF不像RDB，RDB是保存数据集的本身 但是redis进程能够自动的去扫描这个对应的AOF文件，把其中一些冗余的操作给合并一个，以实现将来一次性把数据恢复，也就是说redis能够合并重写AOF的持久化文件，由BGREWRITEAOF命令来实现，BGREWRITEAOF命令是工作于后台的重写AOF文件的命令，重写后redis将会以快照的方式将内存中的数据以命令的方式保存在临时文件中，最后替换原来的文件，重写AOF文件方式，并没有读取旧AOF文件，而是直接将当前内存中的所有数据直接生成一个类似于MySQL二进日志命令一样的操作，例：set cjk 0 ，incr cjk ... 1000 ，则会替换为set cjk 1000 些命令放到重写文件中，如果此过程完成，那么原有的AOF将被删除 BGREWRITEAOF：AOF文件重写； 会读取正在使用AOF文件，而通过将内存中的数据，为内存中的所有数据生成一个命令集，以命令的方式保存到临时文件中，完成之后替换原来的AOF文件；所以AOF文件是通过重写将其变小 4.4 配置文件与RDB相关参数 stop-writes-on-bgsave-error yes //在进行快照备份时，一旦发生错误的话是否停止 rdbcompression yes //RDB文件是否使用压缩，压缩会消耗CPU rdbchecksum yes //是否对RDB文件做校验码检测，此项定义在redis启动时加载RDB文件是否对文件检查校验码，在redis生成RDB文件是会生成校验信息，在redis再次启动或装载RDB文件时，是否检测校验信息，如果检测的情况下会消耗时间，会导致redis启动时慢，但是能够判断RDB文件是否产生错误 dbfilename dump.rdb //定义RDB文件的名称 dir /var/lib/redis //定义RDB文件存放的目录路径 127.0.0.1:6379> config get dir 1) \"dir\" 2) \"/var/lib/redis\" 4.5 配置文件与AOF相关参数 appendonly no //定义是否开启AOF功能，默认为关闭 appendfilename \"appendonly.aof\" //定义AOF文件 appendfsync always //表示每次收到写命令时，立即写到磁盘上的AOF文件，虽然是最好的持久化功能，但是每次有写命令时都会有磁盘的I/O操作，容易影响redis的性能 appendfsync everysec //表示每秒钟写一次，不管每秒钟收到多少个写请求都往磁盘中的AOF文件中写一次 appendfsync no //表示append功能不会触发写操作，所有的写操作都是提交给OS，由OS自行决定是如何写的 no-appendfsync-on-rewrite no //当此项为yes时，表示在重写时，对于新的写操作不做同步，而暂存在内存中 auto-aof-rewrite-percentage 100 //表示当前AOF文件的大小是上次重写AOF文件的二倍时，则自动日志重写过程 auto-aof-rewrite-min-size 64mb //定义AOF文件重写过程的条件，最少为定义大小则触发重要过程 注意：持久本身不能取代备份；还应该制定备份策略，对redis数据库定期进行备份。 4.6 RDB与AOF同时启用 (1) BGSAVE和BGREWRITEAOF不会同时执行，为了避免对磁盘的I/O影响过大，在某一时刻只允许一者执行；如果BGSAV在执行当中，而用户手动执行BGREWRITEAOF时，redis会立即返回OK，但是redis不会同时执行，会等BGSAV执行完成，再执行BGREWRITEAOF (2) 在Redis服务器启动用于恢复数据时，会优先使用AOF 五．redis主从架构（实现读写分离） 5.1 复制的工作过程 主库会基于pingcheck方式检查从库是否在线，如果在线则直接同步数据文件至从服务端，从服务端也可以主动发送同步请求到主服务端，主库如果是启动了持久化功能时，会不断的同步数据到磁盘上，主库一旦收到从库的同步请求时，主库会将内存中的数据同步本地，而后再把同步后到本地的文件再同步给从库，从库得到以后是保存在本地文件中（磁盘），而后则把该文件装载到内存中完成数据重建，链式复制也同步如此，因为主是不区分是真正的主，还是另外一个的从 1、启动一slave 2、slave会向master发送同步命令，请求主库上的数据，不论从是第一次连接，还是非第一次连接，master此时都会启动一个后台的子进程将数据快照保存在数据文件中，然后把数据文件发送给slave 3、slave收到数据文件 以后会保存到本地，而后把文件重载装入内存，完成数据重建 特点： 1、一个Master可以有多个Slave； 2、支持链式复制(一个slave也可以是其他的slave的slave)； 3、Master以非阻塞方式同步数据至slave(master可以同时处理多个slave的读写请求，salve端在同步数据时也可以使用非阻塞方式)； 5.2 启用复制 方法1. 在slave上: > SLAVAOF MASTER_IP MASTER_PORT 例： 127.0.0.1:6379> slaveof 192.168.1.64 6379 //成为从库 OK 方法2. 修改配置文件 # slaveof \\ \\ //修改此项如下 slaveof 192.168.1.64 6379 5.3 其它相关配置 slave-serve-stale-data yes //表示当主服务器不可以用时，则无法判定数据是否过期，此时从服务器仍然接收到读请求时，yes表示仍然响应（继续使用过期数据） slave-read-only yes //启用slave时，该服务器是否为只读 repl-diskless-sync no //是否基于diskless机制进行sync操作，一般情况下如果disk比较慢，网络带宽比较大时，在做复制时，此项可以改为Yes repl-diskless-sync-delay 5 //指定在slave下同步数据到磁盘的延迟时间，默认为5秒，0表示不延迟 slave-priority 100 //指定slave优先级，如果有多个slave时，那一个slave将优先被同步 # min-slaves-to-write 3 //此项表示在主从复制模式当中，如果给主服务器配置了多个从服务器时，如果在从服务器少于3个时，那么主服务器将拒绝接收写请求，从服务器不能少于该项的指定值，主服务器才能正常接收用户的写请求 # min-slaves-max-lag 10 //表示从服务器与主服务器的时差不能够相差于10秒钟以上，否则写操作将拒绝进行 注意：如果master使用requirepass开启了认证功能，从服务器要使用masterauth \\来连入服务请求使用此密码进行认证； 主服务上： # vim /usr/local/redis-3.2.5/redis.conf 修改 # requirepass foobared 改为： requirepass fda 从服务上： # vim /usr/local/redis-3.2.5/redis.conf 修改 # masterauth \\ 改为： masterauth fda 主从复制的问题： 例：有一主三从，如果主服务器离线，那么所有写操作操作则无法执行，为了避免此情况发生，redis引入了sentinel（哨兵）机制 使用sentinel实现主从架构高可用 6.1 sentinel概述 用于管理多个redis服务实现HA； 监控多个redis服务节点 自动故障转移 sentinel也是一个分布式系统，可以在一个架构中运行多个sentinel进程，多个进程之间使用“流言协议”接收redis主节点是否离线，并使用“投票协议”是否实现故障转移，选择哪一个redis的从服务器成为主服务器 6.2 sentinel工作过程 sentinel安装在另外的主机上，sentinel主机既能监控又能提供配置功能，向sentinel指明主redis主服务器即可（仅监控主服务器），sentinel可以从主服务中获取主从架构信息，并分辨从节点，sentinel可以监控当前整个主从服务器架构的工作状态，一旦发现master离线的情况，sentinel会从多个从服务器中选择并提升一个从节点成为主节点，当主节点被从节点取代以后，那么IP地址则发生了，客户所连接之前的主节点IP则不无法连接，此时可以向sentinel发起查询请求，sentinel会告知客户端新的主节点的IP，所以sentinel是redis在主从架构中实现高可用的解决方，sentinel为了误判和单点故障，sentinel也应该组织为集群，sentinel多个节点同时监控redis主从架构，一旦有一个sentinel节点发现redis的主节点不在线时，sentinel会与其他的sentinel节点协商，其他的sentinel节点是否也为同样发现redis的主节点不在线的情况，如果sentinel的多个点节点都发现redis的主节点都为离线的情况，那么则判定redis主节点为离线状态，以此方式避免误判，同样也避免了单点故障. 6.3 启用sentinel redis-sentinel可以理解为运行有着特殊代码的redis，redis自身也可以运行为sentinel，sentinel也依赖配置文件，用于保存sentinel不断收集的状态信息 程序： redis-sentinel /path/to/file.conf redis-server /path/to/file.conf --sentinel 运行sentinel的步骤： (1) 服务器自身初始化（运行redis-server中专用于sentinel功能的代码）； (2) 初始化sentinel状态，根据给定的配置文件，初始化监控的master服务器列表； (3) 创建连向master的连接； 6.4 专有配置文件 /etc/redis-sentinel.conf (1) # sentinel monitor \\ \\ \\ \\ //此项可以出现多次，可以监控多组织redis主从架构，此项用于监控主节点 \\ 自定义的主节点名称，\\ 主节点的IP地址，\\主节点的端口号，\\主节点对应的quorum法定数量，用于定义sentinel的数量，是一个大于值尽量使用奇数，如果sentinel有3个，则指定为2即可，如果有4个，不能够指定为2，避免导致集群分裂，注意，\\为集群名称，可以自定义，如果同时监控有多组redis集群时，\\不能同样 sentinel monitor mymaster 127.0.0.1 6379 2 (2) sentinel down-after-milliseconds \\ \\ //sentinel连接其他节点超时时间，单位为毫秒（默认为30秒） sentinel down-after-milliseconds mymaster 30000 (3) sentinel parallel-syncs \\ \\ //提升主服务器时，允许多少个从服务向新的主服务器发起同步请求 sentinel parallel-syncs mymaster 1 (4) sentinel failover-timeout \\ \\ //故障转移超时时间，在指定时间没能完成则判定为失败，单位为毫秒（默认为180秒） sentinel failover-timeout mymaster 180000 6.5 命令 SENTINEL masters //列出所有监控的主服务器 SENTINEL slaves \\ //获取指定redis集群的从节点 SENTINEL get-master-addr-by-name \\ //根据指定master的名称获取其IP SENTINEL reset //用于重置，包括名称，清除服务器所有运行状态，故障转移、等等 SENTINEL failover \\ //手动向某一组redis集群发起执行故障转移 Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-18 13:32:51 "},"linux/Tomcat环境搭建.html":{"url":"linux/Tomcat环境搭建.html","title":"Tomcat环境搭建","keywords":"","body":"Tomcat环境搭建 模式：B/S模式 端口：8080 Tomcat 服务器是一个免费的开放源代码的 Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试 JSP 程序的首选。 Tomcat 和 IIS 等 Web 服务器一样，具有处理 HTML 页面的功能。不过，Tomcat 处理静态 HTML 的能力不如 Apache 服务器。 MySQL-Connector-Java是MySQL的JDBC驱动包， 用JDBC连接MySQL数据库时必须使用该jar包 Tomcat Native 这个项目可以让 Tomcat 使用 Apache 的 apr 包来处理包括文件和网络IO操作，以提升性能。直接说就是用tomcat-native这个软件来提高tomcat处理静态页面的性能。这个软件在tomcat的bin目录下已经提供，不用单独去下载了！可以tomcat处理静态的性能略逊于apache！ 安装JDK 如果安装了openjdk，请先卸载，否则安装不了oracle官方的jdk yum -y remove java-* [root\\@lewis63 ~]# tar zxf jdk-8u161-linux-x64.tar.gz -C /usr/local/ 设置环境变量： [root\\@lewis63 ~]# vim /etc/profile export JAVA_HOME=/usr/local/jdk1.8.0_161 export JAVA_BIN=/usr/local/jdk1.8.0_161/bin export PATH=${JAVA_HOME}/bin:$PATH export CLASSPATH=.:${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar [root\\@lewis63 ~]# source /etc/profile 安装Tomcat 下载 wget http://mirrors.shu.edu.cn/apache/tomcat/tomcat-9/v9.0.6/bin/apache-tomcat-9.0.6.tar.gz tar zxf apache-tomcat-9.0.6.tar.gz -C /usr/local/ [root\\@lewis63 local]# mv apache-tomcat-9.0.6 tomcat 改名 各目录文件用途： tomcat **\\|---**bin：存放启动和关闭tomcat执行脚本； **\\|---**conf ：存放不同的配置文件（server.xml和web.xml）； **\\|---**lib： 包含Tomcat使用的jar文件.unix平台此目录下的任何文件都被加到Tomcat的classpath中； **\\|---**logs：存放Tomcat执行时的LOG文件； |---webapps：Tomcat的主要Web发布目录（包括应用程序示例）； **\\|---** ROOT：tomcat的家目录 **\\|---** index.jsp：Tomcat的默认首页文件 |---work：存放jsp编译后产生的class文件或servlet文件存放 |---temp：存放Tomcat运行时所产生的临时文件 Tomcat启动脚本 [root\\@lewis63 ~]# vim /etc/init.d/tomcat #!/bin/bash # Tomcat init script for Linux # chkconfig: 2345 96 14 # discription: The Apache Tomcat Server/JSP container JAVA_OPTS='-server -Xms64m -Xmx128m' JAVA_HOME=/usr/local/jdk1.8.0_161 CATALINA_HOME=/usr/local/tomcat $CATALINA_HOME/bin/catalina.sh $* JAVA_OPTS='-server -Xms64m -Xmx128m'是用来设置JAVA相关运行参数的变量 -server 一定要作为第一个参数，在多个CPU时性能佳 -Xms 初始heap（堆）大小，使用最小内存大小，cpu性能高时此值应该设大一些 -Xmx Java heap最大值，使用内存的最大值 上面两个值分配的是JVM的最小和最大值，取决于硬件的物理内存大小，建议为物理内存的一半，不超过80% chmod +x /etc/init.d/tomcat /etc/init.d/tomcat start 启动tomcat服务 [root\\@lewis63 ~]# netstat -anput | grep 8080 tcp6 0 0 :::8080 :::* LISTEN 1891/java 测试Tomcat http://ip:8080/ 点击manager App,需要一个用户名和密码： 创建管理Manger App用户 vim /usr/local/tomcat/conf/tomcat-users.xml 注释去掉，修改为 \\ \\ \\ \\ \\\" roles=\"tomcat\"/\\> \\\" roles=\"tomcat,role1\"/\\> \\\" roles=\"role1\"/\\> 说明 manager-gui：Allows access to the html interface（允许通过web的方式登录查看服务器信息） tomcat8以上还要增加配置（配置远程访问的manager） vim /usr/local/tomcat/conf/Catalina/localhost/manager.xml \\ docBase=\"${catalina.home}/webapps/manager\"> \\ \\ 重启tomcat 搭建基于域名的虚拟主机 [root\\@lewis63 ~]# ls /usr/local/tomcat/conf/ Catalina catalina.properties jaspic-providers.xml logging.properties tomcat-users.xml web.xml catalina.policy context.xml jaspic-providers.xsd server.xml tomcat-users.xsd server.xml是Tomcat的主配置文件（全局）,服务器设置的，例如端口设置，路径设置。 context里设置tomcat数据源，用来连接数据库。 tomcat_users主要是用户名和密码的设置。 web是默认首页等等之类的设置 [root\\@lewis63 ~]# vim /usr/local/tomcat/conf/server.xml \\ \\ \\ \\ \\ \\ [root\\@lewis63 ~]# mkdir -p /var/www/html/{web1,web2} [root\\@lewis63 ~]# echo 'welcome to lewis63.com' > /var/www/html/web1/index.html [root\\@lewis63 ~]# echo 'welcome to lewis63.cn' > /var/www/html/web2/index.html [root\\@lewis63 ~]# vim /etc/hosts 192.168.1.63 lewis.com 192.168.1.63 lewis.cn 重启tomcat 安装tomcat-Native Tomcat Native 是一个利用 APR 来提升Tomcat性能的本地API。Tomcat 可以使用 apr 来提供更好的伸缩性、性能和集成到本地服务器技术。用来提高 tomcat 的性能。 tomcat native 在具体的运行平台上，提供了一种优化技术，它本身是基于 APR（Apache Portable（轻便） Runtime）技术,tomcat 可以利用 apache 的 apr 接口，使用操作系统的部分本地操作，从而提升性能APR 提升的是静态页面处理能力 Linux下，Tomcat启用APR须要三个组件： apr apr-util tomcat-native.tar.gz（Tomcat自带，在bin文件夹下） [root\\@lewis63 ~]# rpm -qa apr apr-1.4.8-3.el7.x86_64 [root\\@lewis63 ~]# rpm -qa apr-util apr-util-1.5.2-6.el7.x86_64 解决依赖 yum –y install apr-devel apr apr-util gcc gcc-c++ openssl-devel openssl tomcat9 在bin下已有tomcat-native [root\\@lewis63 bin]# tar -zxf tomcat-native.tar.gz -C /usr/local/src/ [root\\@lewis63 bin]# cd /usr/local/src/tomcat-native-1.2.16-src/ [root\\@lewis63 native]# ./configure --prefix=/usr/local/tomcat/ --with-apr=/usr/ --with-java-home=/usr/local/jdk1.8.0_161 --with-ssl [root\\@lewis63 native]# make -j 4 && make install 安装完：提示： 需要要/etc/ld.so.conf 添加库路径/usr/local/apr/lib 添加库文件: vim /etc/ld.so.conf /usr/local/apr/lib #添加此行 [root\\@lewis63 native]# ldconfig #使动态库生效 [root\\@lewis63 native]# vim /etc/profile #最下面加入下面一行 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/tomcat/lib [root\\@lewis63 native]# source /etc/profile 重启tomcat：/etc/init.d/tomcat stop; /etc/init.d/tomcat start 看日志看是否支持native cat /usr/local/tomcat/logs/catalina.out | grep Native 安装mysql Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-18 13:33:16 "},"linux/KVM虚拟化.html":{"url":"linux/KVM虚拟化.html","title":"KVM虚拟化","keywords":"","body":"KVM虚拟化 一．虚拟化产品介绍 虚拟化技术： 仿真虚拟化：对系统硬件没有要求,性能最低] 半虚拟化：虚拟机可以使用真机物理硬件，性能高，需要改内核] 只能虚拟和载体同一操作系统 全虚拟化：直接使用物理硬件，性能高 vmware 支持仿真虚拟化 xen 半虚拟化 REHL5自带xen, 安装时需要安装内核 rpm -ivh kernel-xen-xxx.rpm kvm 全虚拟化 RHEL6 自带kvm KVM概述： KVM 即Kernel-based Virtual Machine 基于内核的虚拟机。Qumranet, 依赖于 Intel VT-x， AMD AMD-v KVM是基于内核的虚拟化技术 KVM，是一个开源的系统虚拟化模块，自Linux 2.6.20之后集成在Linux的各个主要发行版本中。它使用Linux自身的调度器进行管理，所以相对于Xen，其核心源码很少。KVM目前已成为学术界的主流VMM(虚拟机监控器)之一。KVM的虚拟化需要硬件支持（如Intel VT技术或者AMD V技术)。是基于硬件的完全虚拟化。而Xen早期则是基于软件模拟的Para-Virtualization。 KVM： 是指基于 Linux 内核的虚拟机(Kernel-based Virtual Machine)。是第一个整合到 Linux 内核的虚拟化技术。在 KVM 模型中，每一个虚拟机都是一个由 Linux 调度程序管理的标准进程，可以在用户空间启动客户机操作系统。KVM支持linux以外的其它系统。比如:windows 一个普通的 Linux 进程有两种运行模式：内核和用户。 KVM 增加了第三种模式：客户模式(有自己的内核和用户模式) XEN ：需要升级内核，只能支持和物理机系统一样的操作系统。 QEMU：是一套由Fabrice Bellard所编写的以GPL许可证分发源码的模拟处理器，在GNU/Linux平台上使用广泛。QEMU具有高速度和跨平台的特性，QEMU能模拟至接近真实电脑的速度。 QEMU能模拟整个电脑系统，包括中央处理器及其他周边设备。 QEMU和vmware一样都是支持仿真虚拟化，效率比较低。 二．配置KVM 前期准备工作 KVM实验拓扑图 (1)虚拟机内存调成2G以上，要在VMware虚拟中安装KVM,然后在KVM中再安装虚拟机 (2)添加一个20G的硬盘，用于存KVM虚拟机 (3)开启BIOS虚拟化支持 注： 只有64位RHEL6以上系统支持KVM。 32位系统不支持。 查看cpu是否支持虚拟化 Intel：cat /proc/cpuinfo | grep --color vmx AMD :cat /proc/cpuinfo | grep --color svm 看看flag有没有上面的vmx或者是svm，有的话就是支持全虚拟化技术 如果看不到ｖｍｘ，是因为 VMware CPU没有开启 VT 技术 安装KVM 2.1安装KVM模块、管理工具和libvirt 先配置本地yum源 [root\\@lewis63 ~]# cat /etc/yum.repos.d/Centos-Base.repo [base] name=CentOS7 baseurl=file:///mnt enabled=1 gpgcheck=0 yum install qemu-kvm libvirt libguestfs-tools virt-install virt-manager libvirt-python –y 说明： qemu-kvm ： kvm主程序， KVM虚拟化模块 virt-manager： KVM图形化管理工具 libvirt： 虚拟化服务 libguestfs-tools : 虚拟机的系统管理工具 virt-install ： 安装虚拟机的实用工具 。比如 virt-clone克隆工具就是这个包安装的 libvirt-python ： python调用libvirt虚拟化服务的api接口库文件 2.2启动服务 systemctl start libvirtd;systemctl enable libvirtd [root\\@lewis63 ~]# systemctl is-enabled libvirtd #查看是不是开机启动 enabled 确定正确加载kvm 模块，检查 KVM 模块是否成功安装 [root\\@lewis63 ~]# lsmod | grep kvm kvm_intel 170086 0 kvm 566340 1 kvm_intel irqbypass 13503 1 kvm 2.3使用virt-manager 命令建立虚拟机 将kvm管理工具从英文界面，切换成中文界面 LANG='zh_CN.UTF-8' 执行virt-manager后，弹出如下界面： 配置KVM网络桥接功能 网桥介绍: 我们经常所说的Bridge设备其实就是网桥设备，也就相当于现在的二层交换机，用于连接同一网段内的所有机器，所以我们的目的就是将网络设备ens33添加到br0，此时br0就成为了所谓的交换机设备，我们物理机的eth0也是连接在上面的。 添加桥接设备br0： 相当于一个二层交换机，目的是让kvm虚拟机通过ens33可以连接外网 安装桥设备工具 rpm -ivh /mnt/Packages/bridge-utils-1.5-9.el7.x86_64.rpm 把etns33绑到br0桥设备上 [root\\@lewis63 ~]# cd /etc/sysconfig/network-scripts/ [root\\@lewis63 network-scripts]# cp ifcfg-ens33 ifcfg-ens33.bak [root\\@lewis63 network-scripts]# vim ifcfg-ens33 TYPE=\"Ethernet\" BOOTPROTO=\"none\" NAME=\"ens33\" DEVICE=\"ens33\" ONBOOT=\"yes\" BRIDGE=\"br0\" 生成桥设备的配置文件 [root\\@lewis63 network-scripts]# vim ifcfg-br0 DEVICE=\"br0\" NM_CONTROLLED=\"yes\" ONBOOT=\"yes\" TYPE=\"Bridge\" BOOTPROTO=none IPADDR=192.168.1.63 NETMASK=255.255.255.0 GATEWAY=192.168.1.254 DNS1=225.5.5.5 注：TYPE=\"Bridge\"　 B大写 systemctl restart network 查看桥接的信息 [root\\@lewis63 network-scripts]# brctl show bridge name bridge id STP enabled interfaces br0 8000.000c290eebb0 no ens33 virbr0 8000.5254001de1ba yes virbr0-nic 新建KVM虚拟机 4.1创建一个分区，用于存放安装好的Linux操作系统 fdisk /dev/sdb fdisk /dev/sdb 。。。 [root\\@lewis63 ~]# lsblk /dev/sdb NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sdb 8:16 0 20G 0 disk └─sdb1 8:17 0 20G 0 part mkfs.xfs /dev/sdb1 #格式化 mount /dev/sdb1 /var/lib/libvirt/images/ #安装虚拟机，默认存放的路径 注：准备系统镜像：把centos7.4镜像上传到/var/lib/libvirt/images/目录下 dd if=/dev/sr0 of=//var/lib/libvirt/images/Centos7.iso [root\\@lewis63 ~]# virt-manage #在linux图形化界面操作 KVM虚拟机常用命令 [root\\@lewis63 ~]# virsh list #列出在运行的虚拟机 [root\\@lewis63 ~]# virsh start centos7.0 #启动centos7.0虚拟机 [root\\@lewis63 ~]# virsh shutdown centos7.0 #关闭centos7.0虚拟机 [root\\@lewis63 ~]# virsh autostart centos7.0 #设置centos7.0虚拟机为物理机开机后，自动启动 测试： reboot后，没有发现kvm虚拟机开机自动启动。 解决： chkconfig --list libvirtd #开机启动了 libvirtd 0:off 1:off 2:off 3:on 4:on 5:on 6:off #设置开机自动挂载sdb1，否则开机启动不了虚拟机 [root\\@lewis63 ~]# echo \"/dev/sdb1 /var/lib/libvirt/images xfs default 0 0\" >> /etc/fstab Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-18 13:31:36 "},"linux/Git使用.html":{"url":"linux/Git使用.html","title":"Git使用","keywords":"","body":"Git使用 Git上传本地项目 1.绑定用户，全局配置 git config --global user.name “xxx” #GitLab中文名 git config --global user.email xxx@xxx.com #邮箱 2.生成ssh key ssh-keygen -t rsa -C “xxx\\@xxx.com” 1）路径确认，直接按回车存默认路径即可 2）直接回车键，这里我们不使用密码进行登录, 用密码太麻烦; 3）直接回车键 默认路径为：c/Users/用户名/.ssh/id_rsa.pub 用写字板打开id_rsa.pub，打开gitlab点击setting版本库，把密钥粘贴到gitlab密钥，允许推送,，部署key后，可以不用用户密码直接获取代码 3.建立本地仓库 在项目根目录 路径 git init 创建git仓库（把该目录变成Git可以管理的仓库） git add . 将所有文件从工作区添加到暂存区 git add file2.txt file3.txt 单个添加到暂存区 git commit -m \"提交文件\" 把文件提交到分支，双引号内是提交注释 注：commit可以一次提交很多文件，所以你可以多次add不同的文件 4.关联github仓库 git remote add origin https://gitlab.bingosoft.net/项目路径 git push origin master 上传本地代码到主干master git pull origin master 同步远程主机分支代码到本地（慎重：容易把本地最新代码弄丢） 二．Git从远程库克隆 git config --global http.sslVerify false 不验证ssl证书 git clone https://gitlab.bingosoft.net/cmbcmp/BSPRJ2018110.git 三．扩展 git branch xxx 创建一个分支 git checkout xxx 切换分支 git branch 查看当前所处分支 git status 仓库当前的状态 git diff 具体修改了什么内容 git log [--pretty=oneline] 查看从最近到最远时间的提交日志 git reset --hard HEAD\\^ 回退到上一个版本 git reflog 记录每一次命令，包括commit id git reset --hard 1093a 回退到某个commit id的版本 参考文献：廖雪峰Git教程 Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-19 11:33:08 "},"linux/Nagios监控.html":{"url":"linux/Nagios监控.html","title":"Nagios监控","keywords":"","body":"nagios监控服务搭建 常见开源监控的对比和选择 cacti： cacti不是监控工具，他是个依赖于SNMP的数据采集和数据呈现的工具。 功能： 数据采集、保存数据[SQL,txt] 数据展示（rrdtool绘图） 数据分析和报警（很一般） nagios： 功能： 数据报警（报警功能是Nagios的特色功能）[故障触发，故障恢复都可以 依赖分析报警（能自动的识别到关键设备的故障，关联设备不会报警） 数据采集（采集的数据是弱项，他只关心警戒位，只关心正常与否的状态，状态转换时可以实现报警，所以它采集的数据不需要保存），当然也有插件弥补这个不足，如PNP4Nagios Nagios+cacti整合互相弥补不足！ zabbix： nagios和cacti不适合超大规模的监控、由于大规模的带宽和网络限制，会导致监控的延迟等问题，所以有很多是nagios+cacti整合，但是依然不适合在大规模的环境中，不适合分布式部署，Nagios在大规模中就会出现延迟，失去Nagios本事的特色。 那么zabbix同时整合了cacti和Nagios特点的工具，而且还具有了前两者不具有的工具，支持分布式等等。 补充工具： netdata：托管在github上的一款类型zabbix的开源监控工具 https:/ /github.com/firehol/netdata open-falcon：小米公司开源的企业级监控工具，用Python写的 Ganglia 类似于zabbix，大型分布式监控系统 数据采集的方式： SNMP：简单网络管理协议 Agent：代理的方式去采集数据 Shell，脚本：通过脚本获取信息来采集 数据展示方式： java、php、APP 报警方式： mail、短信、及时通信工具 一．nagios监控简介 Nagios是一款开源免费的网路监视工具，可以监控的设备：Windows，Linux，Unix，Router，Switch，打印机等，具有报警功能，是一个网络监控系统。在系统或服务状态异常时发出邮件或短信报警第一时间通知网站运维人员，在状态恢复后发出正常的邮件或短信通知。 Nagios运行模式和优点 运行模式：数据收集是C/S模式，用户查看监控信息是B/S模式 优点： 1：监控网路服务状态（HTTPD，FTP，SSH，MySql……） 2：监控主机资源（处理器符合，硬盘利用率……） 3：拓展，根据自己的需求实现拓展检测功能（插件开发） 4：自动日志回滚 5：能够定义网络主机的层次,允许逐级检查,就是从父主机开始向下检查 6：警告，基于状态的警告：OK，Warning（警告），critical（关键），unknown（未知） 7：可以支持并实现对主机的冗余监控 8：Web界面可以查看当前网络状态，通知，问题历史，日志文件等 二．Nagios运行原理 Nagios的功能是监控服务和主机，但是他自身并不包括这部分功能，所有的监控、检测功能都是通过各种插件来完成的。 启动Nagios后，它会周期性的自动调用插件去检测服务器状态，同时Nagios会维持一个队列，所有插件返回来的状态信息都进入队列，Nagios每次都从队首开始读取信息，并进行处理后，把状态结果通过web显示出来。 Nagios提供了许多插件，利用这些插件可以方便的监控很多服务状态。安装完成后，在nagios主目录下的/libexec里放有nagios自带的可以使用的所有插件，如，check_disk是检查磁盘空间的插件，check_load是检查CPU负载的，等等。每一个插件可以通过运行./check_xxx –h 来查看其使用方法和功能。 在大规模生产环境中，如果需要浏览历史数据，需要结合db 获取数据的方式：主动发送、NRPE插件、SNMP、NSClient++ Nagios 通过NRPE 来远端管理服务 Nagios 执行安装在它里面的check_nrpe 插件，并告诉check_nrpe 去检测哪些服务。 通过SSL，check_nrpe 连接远端机子上的NRPE daemon NRPE 运行本地的各种插件去检测本地的服务和状态(check_disk,..etc) 最后，NRPE 把检测的结果传给主机端的check_nrpe，check_nrpe 再把结果送到Nagios状态队列中。 Nagios 依次读取队列中的信息，再把结果显示出来。 三．安装 此方法同样适用新版本 3.1 环境 LAP环境，不需要mysql 需要准备软件包如下： nagios-3.5.1.tar.gz #Nagios核心文件，Nagios服务文件，不建议用最新，很多插件没做好 nagios-plugins-2.1.1.tar.gz #Nagios插件，用于存放脚本和命令 NSCP-0.5.0 #也就是Nsclient++，用来监控Windows，分为64位、32位版本 nrpe-2.15.tar.gz #代理服务，用于监控非Nagios服务器的服务器本地私有信息代理 解决依赖和安装LAP环境 Centos7安装epel源 yum -y install epel-release yum clean all && yum list yum install -y gcc glibc glibc-common php gd gd-devel libpng libmng libjpeg zlib yum install -y httpd systemctl start httpd systemctl enable httpd 3.2 安装nagios 创建Nagios运行用户 useradd nagios groupadd nagcmd Nagios和apache加入该组 usermod -G nagcmd nagios usermod -G nagcmd apache Nagios核心安装 [root\\@lewis63 ~]# mkdir Nagios #所有软件包放在此目录下 [root\\@lewis63 ~]# cd Nagios;ls nagios-3.5.1.tar.gz nagios-plugins-2.1.1.tar.gz nrpe-2.15.tar.gz [root\\@lewis63 Nagios]# tar zxf nagios-3.5.1.tar.gz -C /usr/local/src/ [root\\@lewis63 Nagios]# cd /usr/local/src/nagios/ [root\\@lewis63 nagios]# ./configure --with-command-group=nagcmd [root\\@lewis63 nagios]# make all [root\\@lewis63 nagios]# make install && make install-init && make install-commandmode && make install-config && make install-webconf 若是单步执行，每次执行一部，都会提示你下一步需要干什么 到此时，安装过程就结束，在安装的时候，make install生成share这个目录，这个目录是访问界面目录 说明： 在安装的时候，make install生成share这个目录，这个目录是访问界面目录 在make install-init的时候，生成启动脚本 [root\\@lewis63 ~]# ls /etc/init.d/nagios /etc/init.d/nagios 其实就是在/etc/rc.d/init.d/nagios 在make install-config的时候，生成了Nagios的相关配置文件 [root\\@lewis63 ~]# ls /usr/local/nagios/etc/ cgi.cfg nagios.cfg objects resource.cfg 包括以后安装了plugin等软件后，配置文件也会放入此目录 resource.cfg:定义了很多资源变量的调用 在make install-webconf的时候，已经把web-conf的配置文件放入了/etc/httpd/conf.d/下面 [root\\@lewis63 ~]# ls /etc/httpd/conf.d/nagios.conf /etc/httpd/conf.d/nagios.conf 里面配置了一个别名，直接引用了/usr/local/nagios/share目录 Nagios主目录 [root\\@lewis63 ~]# ll /usr/local/nagios/ bin #Nagios执行程序所在目录 etc #nagios配置文件所在目录，初始安装只有几个*.cfg文件 libexec #监控所用命令，需要安装了nagios-plugins插件了才会有，检测命令，不装是空的 sbin #Nagios的Cgi文件所在目录，外部命令所需要的文件存放目录 share #Nagios前端页面 var #日志文件，pid文件等 认识一下nagios的配置文件 vim /usr/local/nagios/etc/nagios.cfg log_file=/var/log/nagios/nagios.log #日志位置 cfg_file=/etc/nagios/objects/commands.cfg #这个文件定义了很多命令 cfg_file=/etc/nagios/objects/contacts.cfg #定义联系人，怎么联系 cfg_file=/etc/nagios/objects/timeperiods.cfg #定义了时间段 cfg_file=/etc/nagios/objects/templates.cfg #模板（联系人，主机，时间） cfg_file=/etc/nagios/objects/localhost.cfg #监控本机相关配置文件 #cfg_file=/etc/nagios/objects/windows.cfg #windows，默认不监控 #cfg_file=/etc/nagios/objects/switch.cfg #交换机路由器监控，默认不监控 #cfg_file=/etc/nagios/objects/printer.cfg #打印机监控，默认不监控 #cfg_dir=/etc/nagios/servers #定义了服务合集（多个使用） #cfg_dir=/etc/nagios/printers #定义了打印机合集（多个使用） #cfg_dir=/etc/nagios/switches #定义了交换合集（多个使用） #cfg_dir=/etc/nagios/routers #定义了路由合集（多个使用） resource_file=/etc/nagios/private/resource.cfg 资源变量配置文件，包括$USER1$变量（一个路径）等 status_update_interval=10 #状态更新时间，单位s log_rotation_method=d #日志滚动，默认天 service_check_timeout=60 #服务检查超时时间 host_check_timeout=30 #主机检查超时时间 event_handler_timeout=30 notification_timeout=30 ocsp_timeout=5 perfdata_timeout=5 vim /usr/local/nagios/etc/cgi.cfg //此配置文件比nagios.cfg优先级高 main_config_file= /usr/local/nagios/etc/nagios.cfg #主配置文件 physical_html_path= /usr/local/nagios/share #物理路径 url_html_path=/nagios #在URL后面加上/nagios才能访问 use_authentication=1 #使用认证 use_ssl_authentication=0 #不使用ssl authorized_for_system_information=nagiosadmin #认证用户 Nagios访问测试 [root\\@lewis63 ~]# systemctl restart httpd 浏览器打开http://ip/nagios 需要用户名和密码，查看vim /etc/httpd/conf.d/nagios.conf配置文件 在Directory字段里面有Auth这三个字段，那么就可以使用htpasswd来生成用户名和密码 [root\\@lewis63 ~]# htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin New password: Re-type new password: Adding password for user nagiosadmin -c表示创建，二次添加用户，不能使用-c参数 #nagios 默认使用nagiosadmin来管理，如果使用其他用户名，对应的配置文件也要修改 systemctl restart httpd 生成启动脚本 [root\\@lewis63 ~]# chmod +x /etc/init.d/nagios [root\\@lewis63 ~]# vim /usr/lib/systemd/system/nagios.service [Unit] Description=nagios After=network.target [Service] Type=forking ExecStart=/etc/init.d/nagios start ExecReload=/etc/init.d/nagios restart ExecStop=/etc/init.d/nagios stop PrivateTmp=true [Install] WantedBy=multi-user.target 将服务添加到系统启动服务中：systemctl enable nagios 启动nagios服务: systemctl start nagios 或者 /etc/init.d/nagios start 检查配置文件:在nagios的目录下，bin目录下有一个nagios命令，这个命令可以帮助我们对配置文件的检查工作以及指定相关配置文件(下图代表没有问题) [root\\@lewis63 ~]# /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg 3.3安装Nagios-plugins插件 为了后面的实验要求，先把mysql客户端安装了 [root\\@lewis63 ~]# yum -y install mysql mysql-devel Nagios-plugins含有丰富的检测命令插件，安装完成之后放在了/usr/local/Nagios/libexec下面 [root\\@lewis63 Nagios]# tar zxf nagios-plugins-2.1.1.tar.gz -C /usr/local/src/ [root\\@lewis63 Nagios]# cd /usr/local/src/nagios-plugins-2.1.1/ [root\\@lewis63 nagios-plugins-2.1.1]# ./configure --with-nagios-user=nagios --with-nagios-group=nagcmd [root\\@lewis63 nagios-plugins-2.1.1]# make –j 4 && make install 已经有了很多check命令 启动Nagios服务，检查环境 [root\\@lewis63 ~]# systemctl restart httpd; /etc/init.d/nagios restart 浏览器测试：登陆之后，点击hosts，可以看到，默认监控的是本机，说明环境没有什么问题 四．监控本服务器 流程：指定主配置文件需要加载的配置文件—定义主机—定义服务 –定义监控命令—检查配置文件—启动Nagios 监控本地NFS状态 [root\\@lewis63 ~]# cd /usr/local/nagios/etc/objects/ [root\\@lewis63 objects]# cp localhost.cfg localhost.cfg.bak #备份配置文件 [root\\@lewis63 objects]# vim localhost.cfg #NFS define service{ use local-service ; Name of service template to use host_name localhost service_description NFS check_command check_tcp!2049 notifications_enabled 0 } #在使用check命令之前，要确保下/usr/local/nagios/libexec/ 目录下有没有你需要的check命令，如果有，直接调用，如果没有，检测端口来代替，检测格式： check_tcp!端口号 [root\\@lewis63 objects]# vim /etc/exports #创建一个共享 /tmp *(rw) [root\\@lewis63 ~]# systemctl restart nfs [root\\@lewis63 ~]# showmount -e 192.168.1.63 #检测NFS目前是否正常 Export list for 192.168.1.63: /tmp * 检测配置文件是否有误 [root\\@lewis63 ~]# /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg Total Warnings: 0 Total Errors: 0 重启nagios服务：systemctl restart nagios 正在检查，稍等一会 或者手动强制刷新，不需要等待 点击NFS,有个Re-schedule the next check of this service 一般状态有四种颜色，如下图 五．监控远程服务器 5.1Nagios监控远程MYSQL 数据库状态 监控任何一台服务器，工作流程是定义主机，定义服务，定义命令 [root\\@lewis64 ~]# yum -y install mysql mysql-server [root\\@lewis64 ~]# systemctl start mysqld 创建一个测试数据库 [root\\@lewis64 ~]# mysql -uroot –p mysql> create database nagios; mysql> grant select on nagios.* to 'nagios'\\@'192.168.1.63' identified by '123456'; lewis63上配置Nagios服务 [root\\@lewis63 ~]# vim /usr/local/nagios/etc/nagios.cfg 添加下面两行 cfg_file=/usr/local/nagios/etc/objects/hosts.cfg cfg_file=/usr/local/nagios/etc/objects/service.cfg [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/hosts.cfg define host{ use linux-server host_name lewis64 address 192.168.1.64 } [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/service.cfg define service{ use local-service host_name lewis64 service_description MySqlSev check_command check_mysql } [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/commands.cfg #MYSQL command define command{ command_name check_mysql command_line $USER1$/check_mysql -H $HOSTADDRESS$ -u nagios -p123456 -d nagios } 手动检测command.cfg的命令有效性 [root\\@lewis63 ~]# /usr/local/nagios/libexec/check_mysql -H 192.168.1.64 -u nagios -p123456 -d nagios Uptime: 882 Threads: 1 Questions: 7 Slow queries: 0 Opens: 107 Flush tables: 1 Open tables: 100 Queries per second avg: 0.007|Connections=5c;;; Open_files=16;;; Open_tables=101;;; Qcache_free_memory=1031832;;; Qcache_hits=0c;;; Qcache_inserts=0c;;; Qcache_lowmem_prunes=0c;;; Qcache_not_cached=1c;;; Qcache_queries_in_cache=0;;; Queries=8c;;; Questions=5c;;; Table_locks_waited=0c;;; Threads_connected=1;;; Threads_running=1;;; Uptime=882c;;; 注意：所有的check_command字段中的所使用的命令，必须在command.cfg中定义好才能使用，而command.cfg中的command_line中使用的命令，必须在/usr/local/Nagios/libexec/目录下存在，安装plugins会生成 注意：服务器要安装了mysql客户端软件，然后再重新编译安装下plugins 才会生成check_mysql [root\\@lewis64 ~]# systemctl stop mysqld #lewis64停掉服务再检测 [root\\@lewis63 ~]# /usr/local/nagios/libexec/check_mysql -H 192.168.1.64 -u nagios -p123456 -d nagios Can't connect to MySQL server on '192.168.1.64' (111) [root\\@lewis63 ~]# systemctl restart nagios 刚才已停掉数据库 监控提示警告严重状态 [root\\@lewis64 ~]# systemctl start mysqld #lewis64 重新启动mysql服务 5.2定义监控web服务 [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/hosts.cfg define host{ use linux-server host_name lewis64 address 192.168.1.64 } #上面定义过lewsis64的主机，无需重复定义 [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/service.cfg define service{ use local-service host_name lewis64 service_description Nginx check_command check_nginx } [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/commands.cfg #Nginx command define command{ command_name check_nginx command_line $USER1$/check_tcp -H $HOSTADDRESS$ -p 80 } [root\\@lewis63 ~]# /etc/init.d/nagios restart #重启测试nginx 5.3 Nagios监控外部主机私有信息 私有信息，包括默认的硬盘使用，进程数目，SWAP分区等等 私有信息，就是我需要在本机登陆操作登陆的 非私有，就是可以通过远程的方式 只有监控私有信息的时候，才调用NRPE这个插件来通信 nrpe插件 通过NRPE（一个插件）服务可以添加本地信息的监控，将数据发送到我们的Nagios服务器 NRPE两部分组成，一部分是监控机check_nrpe，一部分是被监控机的NRPE守护进程 Nagios 服务器执行check_nrpe 插件并告诉他检查哪个服务，check_nrpe 插件通过SSL 连接方式联系远程服务器上的NRPE守护进程，NRPE守护进程执行相应的插件完成指定的检查，并返回结果。 Nrpe是基于SSL的机制，那么我们需要做的事情就是构建SSL环境，所以需要使用NRPE工作的时候，都需要安装SSL，而且服务端和客户端都需要安装nrpe软件，而我们客户端不需要安装NAGIOS服务端 解决依赖 实验所需设备都需要安装SSL的支持 [root\\@lewis63 ~]# yum -y install openssl openssl-devel [root\\@lewis64 ~]# yum -y install openssl openssl-devel [root\\@lewis63 Nagios]# tar zxf nrpe-2.15.tar.gz -C /usr/local/src/ [root\\@lewis63 ~]# cd /usr/local/src/nrpe-2.15/ [root\\@lewis63 nrpe-2.15]# ./configure && make && make install #安装插件 [root\\@lewis63 nrpe-2.15]# make install-plugin && make install-daemon #以守护进程运行 [root\\@lewis63 nrpe-2.15]# ls /usr/local/nagios/libexec/check_nrpe /usr/local/nagios/libexec/check_nrpe #这个命令需要安装nrpe才会有 客户端配置 需要安装nagios-plugins nrpe [root\\@lewis64 ~]# useradd -s /sbin/nologin nagios [root\\@lewis64 ~]# groupadd nagcmd [root\\@lewis64 ~]# usermod -G nagcmd nagios [root\\@lewis64 ~]# yum -y install xinetd [root\\@lewis64 ~]# tar zxf nagios-plugins-2.1.1.tar.gz -C /usr/local/src/ [root\\@lewis64 ~]# tar zxf nrpe-2.15.tar.gz -C /usr/local/src/ [root\\@lewis64 ~]# cd /usr/local/src/nagios-plugins-2.1.1/ [root\\@lewis64 nagios-plugins-2.1.1]# ./configure && make && make install [root\\@lewis64 nagios-plugins-2.1.1]# cd ../nrpe-2.15/ [root\\@lewis64 nrpe-2.15]# ./configure && make && make install [root\\@lewis64 nrpe-2.15]# make install-daemon-config #客户端，不用make-install-plugin [root\\@lewis64 nrpe-2.15]# make install-xinetd [root\\@lewis64 ~]# vim /etc/xinetd.d/nrpe service nrpe { flags = REUSE socket_type = stream port = 5666 wait = no user = nagios group = nagios server = /usr/local/nagios/bin/nrpe server_args = -c /usr/local/nagios/etc/nrpe.cfg --inetd log_on_failure += USERID disable = no only_from = 127.0.0.1 192.168.1.63 #添加红色 nagios服务器地址, 允许63这台机器来连接自己的nrpe服务，多个IP地址空格分隔 } [root\\@lewis64 ~]# echo \"nrpe 5666/tcp #NRPE\" >> /etc/services #端口注册 /etc/services文件的作用： 作用1：xinet.d来启动服务时他就会在/etc/services找相应服务对应的端口来启动服务。找不到对应端口，将不启动服务。 作用2: 显示对应端口对应的协议名。 例如 iptables -L 不加-n参数， 查看时，把 80转 -> www http 作用3：查看常用端口 [root\\@lewis64 ~]# systemctl restart xinetd [root\\@lewis64 ~]# systemctl enable xinetd [root\\@lewis64 ~]# netstat -anput | grep 5666 tcp6 0 0 :::5666 :::* LISTEN 27191/xinetd 客户端nrpe命令 [root\\@lewis64 ~]# swapon –s #查看swap挂载 使用情况 Filename Type Size Used Priority /dev/dm-1 partition 2097148 0 -1 [root\\@lewis64 ~]# vim /usr/local/nagios/etc/nrpe.cfg command[check_load]=/usr/local/nagios/libexec/check_load -w 15,10,5 -c 30,25,20 command[check_root]=/usr/local/nagios/libexec/check_disk -w 20% -c 10% -p /dev/mapper/centos-root command[check_swap]=/usr/local/nagios/libexec/check_disk -w 20% -c 10% -p /dev/dm-1 command[check_total_procs]=/usr/local/nagios/libexec/check_procs -w 150 -c 200 -w为警告 -C为告急，swap中，是指剩余20%告警，10%告急 服务端手动测试 [root\\@lewis63 libexec]# ./check_nrpe -H 192.168.1.64 NRPE v2.15 [root\\@lewis63 ~]# /usr/local/nagios/libexec/check_nrpe -H 192.168.1.64 -c check_root DISK OK - free space: / 7480 MB (73% inode=98%);| /=2749MB;8184;9207;0;10230 如果出现以一下错误，说明没有允许192.168.1.63 访问我们的lewis64服务 #CHECK_NRPE: Error - Could not complete SSL handshake. 我们需要检查/etc/init.d/nrpe 下面的only from中的有无添加192.168.1.63 定义被监控主机 [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/hosts.cfg define host{ use linux-server host_name lewis64 address 192.168.1.64 } 定义需要监控的服务，分别监控root分区 swap分区 进程总数 负载 [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/service.cfg define service{ use local-service host_name lewis64 service_description root_Parition check_command check_nrpe!check_root } define service{ use local-service host_name lewis64 service_description swap_Parition check_command check_nrpe!check_swap } define service{ use local-service host_name lewis64 service_description Total Processes check_command check_nrpe!check_total_procs } define service{ use local-service host_name lewis64 service_description Current Load check_command check_nrpe!check_load } 定义NRPE监控命令 [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/commands.cfg define command{ command_name check_nrpe command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$ } $ARG1$ 表示调用后面的参数 [root\\@lewis63 ~]# /etc/init.d/nagios restart 总结： 1: 服务端监控（无需NRPE） 定义主机，定义服务，定义命令，测试命令，启动 2：有NRPE的监控 定义主机，定义服务（check_nrpe!check_ping）,定义命令（定义的是check_nrpe） 3：还有一个定义命令（客户端做 command[check_adfadf]） -w –c 安装好之后，是依赖于xinetd服务启动的 六．配置邮件报警 [root\\@lewis63 ~]# yum install -y sendmail mailx –y [root\\@lewis63 ~]# systemctl start sendmail [root\\@lewis63 ~]# systemctl enable sendmail [root\\@lewis63 ~]# vim /usr/local/nagios/etc/objects/contacts.cfg define contact{ contact_name nagiosadmin use generic-contact alias Nagios Admin email 921736904@qq.com #修改为自己的邮箱 } [root\\@lewis63 ~]# vim /usr/local/nagios/etc/nagios.cfg enable_notifications=1 #开启邮件告警 [root\\@lewis63 ~]# vim /etc/mail.rc set from=xiaokai0312\\@163.com set smtp=smtp.163.com set smtp-auth-user=xiaokai0312\\@163.com set smtp-auth-password=xxx #授权码 set smtp-auth=login [root\\@lewis64 ~]# systemctl stop mysqld #停止mysql服务 [root\\@lewis63 ~]# /etc/init.d/nagios restart 七．安装pnp4nagios图形分析 参考：https://blog.csdn.net/jie_linux/article/details/78604426 安装组件 [root\\@lewis63 ~]# yum –y install perl-Time-HiRes rrdtool rrdtool-perl [root\\@lewis63 ~]# tar zxf pnp4nagios-0.6.26.tar.gz -C /usr/local/src/ [root\\@lewis63 ~]# cd /usr/local/src/pnp4nagios-0.6.26/ [root\\@lewis63 pnp4nagios-0.6.26]# ./configure --prefix=/usr/local/nagios/pnp4nagios --with-nagios-user=nagios --with-nagios-group=nagcmd [root\\@lewis63 pnp4nagios-0.6.26]# make all [root\\@lewis63 pnp4nagios-0.6.26]# make install && make install-webconf && make install-config && make install-init [root\\@lewis63 etc]# mv misccommands.cfg-sample misccommands.cfg [root\\@lewis63 etc]# mv nagios.cfg-sample nagios.cfg [root\\@lewis63 etc]# mv rra.cfg-sample rra.cfg [root\\@lewis63 etc]# pwd /usr/local/nagios/pnp4nagios/etc [root\\@lewis63 etc]# cd pages/ [root\\@lewis63 pages]# mv web_traffic.cfg-sample web_traffic.cfg [root\\@lewis63 pages]# cd ../check_commands/ [root\\@lewis63 check_commands]# mv check_all_local_disks.cfg-sample check_all_local_disks.cfg [root\\@lewis63 check_commands]# mv check_nrpe.cfg-sample check_nrpe.cfg [root\\@lewis63 check_commands]# mv check_nwstat.cfg-sample check_nwstat.cfg 启动npcd [root\\@lewis63 ~]# /usr/local/nagios/pnp4nagios/bin/npcd -d -f /usr/local/nagios/pnp4nagios/etc/npcd.cfg [root\\@lewis63 ~]# chkconfig npcd on [root\\@lewis63 ~]# vim /usr/local/nagios/etc/nagios.cfg 将process_performance_data=0 修改为 process_performance_data=1 将以下两项的#去掉 host_perfdata_command=process-host-perfdata service_perfdata_command=process-service-perfdata Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-19 13:13:30 "},"linux/zabbix源码安装及配置.html":{"url":"linux/zabbix源码安装及配置.html","title":"zabbix源码安装及配置","keywords":"","body":"zabbix源码搭建 环境：LNMP+zabbix3.4 整个环境所需要的软件包 php-5.6.13 libmcrypt-2.5.8 mysql-5.6.26 nginx-1.8.0 zabbix-3.4.3 创建导入zabbix数据库 [root\\@lewis63 ~]# mysql -uroot -p mysql> create database zabbix; mysql> create database zabbix; mysql> flush privileges; [root\\@lewis63 ~]# tar zxf zabbix-3.4.3.tar.gz -C /usr/local/src/ [root\\@lewis63 ~]# cd /usr/local/src/zabbix-3.4.3/ 导入数据库，注意顺序，否则会报错 [root\\@lewis63 zabbix-3.4.3]# mysql -uzabbix -pzabbix zabbix \\ [root\\@lewis63 zabbix-3.4.3]# mysql -uzabbix -pzabbix zabbix \\ [root\\@lewis63 zabbix-3.4.3]# mysql -uzabbix -pzabbix zabbix \\ 编译zabbix [root\\@lewis63 ~]# groupadd zabbix [root\\@lewis63 ~]# useradd -s /sbin/nologin -g zabbix zabbix #创建用户 解决依赖 yum install -y net-snmp-devel yum install -y libevent libevent-devel [root\\@lewis63 zabbix-3.4.3]# ./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql=/var/lib/mysql/bin/mysql_config --with-net-snmp --with-libcurl参数说明: --prefix= #指定路径 --enable-server #Server 支持 --enable-agent #支持 Zabbix 客户端 --with-mysql #指定 MySql 库可以选择自定路径 mysql_config，mysql_config 是命令，用于编译 mysql 客户端程序 --with-net-snmp #支持 snmp 协议，需要安装 net-snmp-devel 包 --with-libcurl #支持 CURL 功能，libcurl 主要功能就是用不同的协议连接不同的服务器， libcurl 当前支持的协议有 http，https，ftp，gopher，telent，dict，file，和 ldap 协议 其他参数： --enable-proxy 指的是支持 zabbix 代理服务器，zabbix proxy 是一个监控代理服务器，它收集到监控数据，选存放在缓冲区，保存的时间可以通过配置文件设定，然后再传送的 zabbix server。监控代理服务需要一个独立的数据库。 用 zabbix proxy 的好处：进程监控，当监控的位置通信不便时，当通讯上千台设备的时候，使用 zabbix_proxy 可以简化维护分布式监控，降低 zabbix server 的负负载 *********************************************************** * Now run 'make install' * * * * Thank you for using Zabbix! * * \\http://www.zabbix.com\\ * #按上面的提示，没有 make 步骤，直接 make install [root\\@lewis63 zabbix-3.4.3]# make install 3.配置 zabbix Server [root\\@lewis63 ~]# vim /usr/local/zabbix/etc/zabbix_server.conf DBHost=localhost #默认注释掉了，直接取消注释即可 DBName=zabbix #数据库用户，我们授权的用户也是zabbix DBUser=zabbix #默认是 root，我们授权的用户是 zabbix DBPassword=zabbix #密码我们授权的也是 zabbix 4.监控 Zabbix Server 本身 监控本身，意思是本身作为服务器之外，自己也做自己的客户端，也要使用agentd这个代理者 配置文件中，有 agentd 和 agent 两个配置文件，前者是守护进程，后者依赖 xinetd [root\\@lewis63 ~]# vim /usr/local/zabbix/etc/zabbix_agentd.conf Server=127.0.0.1 #默认监控服务器自己，这三行不用改 ServerActive=127.0.0.1 Hostname=Zabbix server UnsafeUserParameters=1 #允许所有的字符是在用户定义的参数，参数传递，也就是支持自定义脚本 其中 Server 和 ServerActive 都指定 zabbixserver 的 IP 地址，不同的是，前者是被动后者是主动。也就是说前者允许 127.0.0.1 这个 ip 来我这取数据。而 serverActive 的 127.0.0.1 的意思是，客户端主动提交数据给他 5.启动服务 直接运行 [root\\@lewis63 ~]# /usr/local/zabbix/sbin/zabbix_server /usr/local/zabbix/sbin/zabbix_server: error while loading shared libraries: libmysqlclient.so.18: cannot open shared object file: No such file or directory 报错解决 [root\\@lewis63 ~]# vim /etc/ld.so.conf #解决库文件找不到 include ld.so.conf.d/*.conf /usr/local/mysql/lib/ #根据实际路径添加此行 [root\\@lewis63 ~]# ldconfig #使库文件生效 [root\\@lewis63 ~]# echo /usr/local/zabbix/sbin/zabbix_server >> /etc/rc.local #开机启动 [root\\@lewis63 ~]# /usr/local/zabbix/sbin/zabbix_server [root\\@lewis63 ~]# netstat -anput | grep zabbix_server tcp 0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 55457/zabbix_server #server 运行端口 10051 6. 编辑 php 页面控制文件 默认配置文件没有写入到我们的 Nginx 的配置文件中，也就是不能加载到我们的 zabbix 页面目录 [root\\@lewis63 ~]# cp -r /usr/local/src/zabbix-3.4.3/frontends/php/* /usr/local/nginx/html/ [root\\@lewis63 ~]# vim /usr/local/nginx/conf/nginx.conf location / { root html; index index.php index.html index.htm; #找到此行内容，添加index.php } 重启nginx服务和php-fpm服务 [root\\@lewis63 ~]# nginx -s reload [root\\@lewis63 ~]# /etc/init.d/zabbix_server restart [root\\@lewis63 ~]# /etc/init.d/php-fpm restart 打开网页安装 zabbix web 打开浏览器输入http://192.168.1.63 开始检查环境 编辑 php.ini 文件，修改环境 [root\\@lewis63 ~]# vim /usr/local/php/php.ini post_max_size = 16M #修改 max_execution_time = 300 #修改 max_input_time = 300 #修改 date.timezone = Asia/Shanghai #此行有注释，去注释并修改 always_populate_raw_post_data = -1 #此行取消注释即可 mysqli.default_socket = /var/lib/mysql/mysql.sock #指定php连接mysql的sock路径 [root\\@lewis63 ~]# /etc/init.d/php-fpm restart#重启fpm 刷新页面 如果提示没有安装PHP LDAP模块，为了不影响后面的功能，现在把这个模块重新编译安装进去 [root\\@lewis63 ~]# cd /usr/local/src/php-7.0.18/ext/ldap/ [root\\@lewis63 ldap]# /usr/local/php/bin/phpize Configuring for: PHP Api Version: 20151012 Zend Module Api No: 20151012 Zend Extension Api No: 320151012 [root\\@lewis63 ldap]# ./configure --with-php-config=/usr/local/php/bin/php-config --with-ldap 上面的过程会报错,提示缺少库文件 yum install openldap-devel openldap –y [root\\@lewis63 ~]# rsync -avz /usr/lib64/libldap* /usr/lib/ 再次编译，即可通过 [root\\@lewis63 ldap]# ./configure --with-php-config=/usr/local/php/bin/php-config --with-ldap [root\\@lewis63 ldap]# make && make install [root\\@lewis63 ldap]# vim /usr/local/php/php.ini 添加：extension=ldap.so [root\\@lewis63 ldap]# /etc/init.d/php-fpm restart 再次刷新即可 这里Database host 需要改为127.0.0.1 下载这个配置文件上传上去 [root\\@lewis63 ~]# mv zabbix.conf.php /usr/local/nginx/html/conf 然后刷新 默认用户名和密码分别为 Admin，zabbix 点击右上角用户，然后选择语言 点击配置-主机 启用本主机（默认没有启动，点击后面红色的停用，则启用） 把zabbix_agent 也启动起来 [root\\@lewis63 ~]# /usr/local/zabbix/sbin/zabbix_agentd 再次刷新页面，可以看到，agent状态已经正常 可以看到已经开始出图 7.图表字符乱码的解决办法 在window系统C:\\Windows\\Fonts找到一个ttf字体文件， [root\\@lewis63 ~]# cd /usr/local/nginx/html/fonts/ [root\\@lewis63 ~]# mv DejaVuSans.ttf DejaVuSans.bak [root\\@lewis63 ~]# mv simli.ttf DejaVuSans.ttf #重命名成DejaVuSans.ttf 二．配置监控远程主机 2.1客户端安装配置 1.解决依赖： [root\\@lewis64 ~]# yum install -y curl curl-devel net-snmp net-snmp-devel perl-DBI [root\\@lewis64 ~]# useradd -M -s /sbin/nologin zabbix [root\\@lewis64 ~]# tar zxf zabbix-3.4.3.tar.gz -C /usr/local/src/ [root\\@lewis64 ~]# cd /usr/local/src/zabbix-3.4.3/ [root\\@lewis64 zabbix-3.4.3]# ./configure --prefix=/usr/local/zabbix --enable-agent [root\\@lewis64 zabbix-3.4.3]# make install [root\\@lewis64 ~]# cat /etc/services|grep zabbix zabbix-agent 10050/tcp # Zabbix Agent zabbix-agent 10050/udp # Zabbix Agent zabbix-trapper 10051/tcp # Zabbix Trapper zabbix-trapper 10051/udp # Zabbix Trapper 2.启动agent [root\\@lewis64 ~]# /usr/local/zabbix/sbin/zabbix_agentd [root\\@lewis64 ~]# cp /usr/local/src/zabbix-3.4.3/misc/init.d/fedora/core5/zabbix_agentd /etc/init.d/ [root\\@lewis64 ~]# vim /etc/init.d/zabbix_agentd ZABBIX_BIN=\"/usr/local/zabbix/sbin/zabbix_agentd\" #修改此行 [root\\@lewis64 ~]# chkconfig --add zabbix_agentd [root\\@lewis64 ~]# chkconfig zabbix_agentd on 配置 Agentd 的配置文件 [root\\@lewis64 ~]# vim /usr/local/zabbix/etc/zabbix_agentd.conf Server=192.168.1.63 #zabbix server 地址，可以多个，用，隔开 ServerActive=192.168.1.63 #主动检查的意思,主动检查主机的数据的数据发送给 Zabbix Server Hostname=lewis64 UnsafeUserParameters=1 重启服务：[root\\@lewis64 ~]# /etc/init.d/zabbix_agentd restart [root\\@lewis64 ~]# netstat -anput | grep zabbix tcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 8544/zabbix_agentd Server 端测试通讯 [root\\@lewis63 ~]# /usr/local/zabbix/bin/zabbix_get -s 192.168.1.64 -p10050 -k system.uname Linux lewis64 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 #可以获取对方系统版本则证明没有问题 2.2服务端添加 Host 主机 选择模板 点选择，选择Template OS Linux，点击两次添加 远程主机已经被添加进来，启用该主机，可用性变成绿色即可出图监控 2.3添加监控项 筛选无触发器，出来很多监控项，默认都是启用状态，我们无需再次启动，下面修改自动发现的时间 文件系统探测和网络流量探测 把原来的1h改成10s 修改更新数据后，再次返回图形监控页面，稍等几分钟再次查看监控项 返回主页，可以看到整体的监控状态 2.4设置 Triger 触发器值 默认的值是20% 修改成自己设定的值15% 2.5更新数据 自定义绘图颜色，找到主机对应的模块---修改模板对应的图形颜色 根据需求修改每一个项的显示颜色 总结 zabbix 的文件 zabbix_agent.conf 是用超级服务（xinetd）的方式来启动的，被动检查，只有 Server 说检查的时候才检查 zabbix_agentd.conf 是以独立进程的方式来启动的，一般使用这个来做配置，自动检查，自动提交 zabbix_server.conf Server 启动配置文件，只有一个 zabbix_get 是 Zabbix 中的一个程序，用于 Zabbix-Server 到 Zabbix-Agent 的数据获取，通常可以用来 检测验证 Agent 的配置是否正确。它的使用方法如下 zabbix_get [-hV] -s \\ [-p \\] [-I \\] -k \\ -h：远程 Zabbix-Agent 的 IP 地址或者是主机名。 -p：远程 Zabbix-Agent 的端口。 -I：本机出去的 IP 地址，用于一台机器中有多个网卡的情况。 -k：获取远程 Zabbix-Agent 数据所使用的 Key。 [expmple\\@~]# zabbix_get -s 192.168.0.64 -k system.uname zabbix_sender 与 get 相反，用来发送 Zabbix 服务器处理性能数据。该工具通常用于长时间运行的用户脚 本，用于定期发送可用性和性能数据。使用方法如下 zabbix_sender [-Vhv] {[-zpsI] -ko | [-zpI] -T -i \\ -r} [-c \\] 参数说明： -c --config \\ 配置文件绝对路径 -z --zabbix-server \\ zabbix server 的 IP 地址 -p --port \\ zabbix server 端口.默认 10051 -s --host \\ 主机名，zabbix 里面配置的主机名（不是服务器的 hostname），不能使用 ip 地址 -I --source-address \\ 源 IP -k --key \\ 监控项的 key -o --value \\ key 值 -i --input-file \\ 从文件里面读取 hostname、key、value 一行为一条数据，使用空格作为分 隔符，如果主机名带空格，那么请使用双引号包起来 -T --with-timestamps 一行一条数据，空格作为分隔符: \\\\\\ \\，配合 --input-file option，timestamp 为 unix 时间戳 -r --real-time 将数据实时提交给服务器 -v --verbose 详细模式, -vv 更详细 三．zabbix监控Apache服务 http://www.zabbix.org/wiki/Main_Page https://github.com/zabbix/zabbix-community-repos 各种模板 http://www.douglas.wiki.br/doku.php?id=en:installing_and_configuring_zabbix 下载脚本wget https://github.com/lorf/zapache/archive/master.zip 3.1启用apache 服务器状态，开启apache的server-status [root\\@lewis64 ~]# vim /etc/httpd/conf/httpd.conf 在末尾加入 ExtendedStatus On \\ SetHandler server-status Order allow,deny Allow from 127.0.0.1 192.168.1.0/24 \\ [root\\@lewis64 ~]# systemctl restart httpd 重启后测试 [root\\@lewis64 ~]# unzip zapache-master.zip [root\\@lewis64 ~]# cd zapache-master [root\\@lewis64 zapache-master]# ls httpd-server-status.conf.sample userparameter_zapache.conf.sample zapache-template-active.xml README.md zapache zapache-template.xml 说明： httpd-server-status.conf.sample 是用于配置server-status的上个步骤已经配置过了 userparameter_zapache.conf.sample zapache 关键的文件 zapache-template-active.xml zapache-template.xml模板 3.2将解压出来的几个文件放到相应目录 [root\\@lewis64 zapache-master]# cp zapache /usr/local/bin/ [root\\@lewis64 zapache-master]# cp userparameter_zapache.conf.sample /usr/local/zabbix/etc/zabbix_agentd.conf.d/ [root\\@lewis64 zapache-master]# cd !$ [root\\@lewis64 zabbix_agentd.conf.d]# mv userparameter_zapache.conf.sample userparameter_zapache.conf #重命名 UserParameter=zapache[*],/var/lib/zabbixsrv/externalscripts/zapache \\$1 改为UserParameter=zapache[*],/usr/local/bin/zapache \\$1 [root\\@lewis64 ~]# chmod +x /usr/local/bin/zapache 3.3修改zabbix -agentd.conf [root\\@lewis64 ~]# vim /usr/local/zabbix/etc/zabbix_agentd.conf Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/ #启用引用此目录文件 3.4前端页面操作 导入模板 选择配置->模板 导入 关联模板 配置->主机 选择lewis64 apache客户端 查看最新数据，筛选Apache，可以选择生产图形 四．配置 zabbix 监控 MySQL 和监控我们的 Apache 一样，寻找合适的脚本，不过，脚本并不是那么容易就可以找得到的! 要么自己手动去写，要么自己找到的拿来修改，都是需要花费代价的！ZABBIX 默认提供了 MYSQL 的监控模板 数据库用户授权 mysql> grant usage on *.* to zabbix\\@'%' identified by '123456'; mysql> flush privileges; [root\\@lewis64 ~]# cp /usr/local/src/zabbix-3.4.3/conf/zabbix_agentd/userparameter_mysql.conf /usr/local/zabbix/etc/zabbix_agentd.conf.d/ [root\\@lewis64 ~]# vim /usr/local/zabbix/etc/zabbix_agentd.conf Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf #启用并修改 建立数据库和 zabbix 的链接信息 [root\\@lewis64 ~]# vim /usr/local/zabbix/etc/.my.cnf #Zabbix Agent [mysql] host=lewis63 user=zabbix password=123456 socket= /var/lib/mysql/mysql.sock [mysqladmin] host=lewis63 user=zabbix password=123456 socket= /var/lib/mysql/mysql.sock [root\\@lewis64 ~]# vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/userparameter_mysql.conf 将 HOME=/var/lib/zabbix 全部改成 HOME=/usr/local/zabbix/etc/ # For all the following commands HOME should be set to the directory that has .my.cnf file with password information.（提示目录下必须有.my.cnf） 模板应用主机 选择配置->主机->选择模板 五．Zabbix邮件报警配置 第一步：首先安装mailx组件并配置好能够通过三方邮箱发送邮件 [root\\@lewis63 ~]# yum -y install mailx 然后编辑mailx的配置文件 [root\\@lewis63 ~]# vim /etc/mail.rc set from=xiaokai0312\\@163.com set smtp=smtp.163.com set smtp-auth-user=xiaokai0312\\@163.com set smtp-auth-password=你的授权码 set smtp-auth=login 保存退出后测试邮件是否能够正常发送出去 [root\\@lewis63 ~]# echo \"zabbix test mail\" |mailx -s \"zabbix\" xxxxxx@qq.com 在zabbix服务端写邮件发送脚本 [root\\@lewis63 ~]# cd /usr/local/zabbix/share/zabbix/alertscripts/ [root\\@lewis63 alertscripts]# vim sendmail.sh #!/bin/bash messages=`echo $3 | tr '\\r\\n' '\\n'` subject=`echo $2 | tr '\\r\\n' '\\n'` echo \"${messages}\" | mailx -s \"${subject}\" $1 >>/tmp/sendmail.log 2>&1 [root\\@lewis63 alertscripts]# chown zabbix.zabbix sendmail.sh [root\\@lewis63 alertscripts]# chmod +x sendmail.sh 修改主配置文件，让服务读取到这个脚本 [root\\@lewis63 ~]# vim /usr/local/zabbix/etc/zabbix_server.conf 修改： # AlertScriptsPath=${datadir}/zabbix/alertscripts 为 AlertScriptsPath=/usr/local/zabbix/share/zabbix/alertscripts [root\\@lewis63 ~]# /usr/local/zabbix/share/zabbix/alertscripts/sendmail.sh xxxx\\@qq.com \"测试标题\" \"测试邮件内容\" [root\\@lewis63 ~]# chmod 777 /tmp/sendmail.log 页面添加 管理->报警媒介类型->创建媒体类型 {ALERT.SENDTO} {ALERT.SUBJECT} {ALERT.MESSAGE} 很多人安装zabbix 3.0之后，写的脚本一直发信不成功,手动执行时可以的。 这是因为zabbix3.0之后，可以自定义参数了。所以不写参数，它是不会传参数的。 在2.x版本不存在这个问题，默认会传3个参数 点管理->用户->点击Admin->再点报警媒介->添加 配置->动作->创建动作 名称：Action-Email 操作： 默认接收人：故障{TRIGGER.STATUS},服务器:{HOSTNAME1}发生: {TRIGGER.NAME}故障! 默认信息： 告警主机:{HOSTNAME1} 告警时间:{EVENT.DATE} {EVENT.TIME} 告警等级:{TRIGGER.SEVERITY} 告警信息: {TRIGGER.NAME} 告警项目:{TRIGGER.KEY1} 问题详情:{ITEM.NAME}:{ITEM.VALUE} 当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1} 事件 ID:{EVENT.ID} 恢复操作 默认接收人：已恢复！{TRIGGER.STATUS}, 服务器:{HOSTNAME1}: {TRIGGER.NAME} 恢复信息： 告警主机:{HOSTNAME1} 告警时间:{EVENT.DATE} {EVENT.TIME} 告警等级:{TRIGGER.SEVERITY} 告警信息: {TRIGGER.NAME} 告警项目:{TRIGGER.KEY1} 问题详情:{ITEM.NAME}:{ITEM.VALUE} 当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1} 事件 ID:{EVENT.ID} 测试，关闭 zabbix 客户端服务 zabbix_agentd [root\\@lewis64 ~]# /etc/init.d/zabbix_agentd stop 延迟比较大，大概要5-10分钟 可以在日志看送达状态，qq邮箱微信(绑定qq邮箱)同时收到告警 配置 zabbix 自动发现并监控（监控Ｗｉｎｄｏｗｓ为案例） 首先下载安装Ｗｉｎｄｏｗｓ端ａｇｅｎｔ https://www.zabbix.com/downloads/3.4.6/zabbix_agents_3.4.6.win.zip 找到conf下的配置文件 zabbix_agentd.win.conf (建议用文本编辑软件打开)，修改LogFile、Server、ServerActive、Hostname这四个参数。具体配置如下： LogFile=c:\\zabbix_agentd.log Server=192.168.1.63 Hostname=iqsz-l0001 ServerActive=192.168.1.63 #zabbix server地址 其中logfile是zabbix日志存放地址。Server 是zabbix服务端ip地址。Hostname是本机机器名。 以管理员身份运行切换至agent存放位置，比如D:\\zabbix_agent\\bin\\win64，否则会报错 安装windos zabbix客户端 zabbix_agentd.exe -c D:\\zabbix_agent\\conf\\zabbix_agentd.win.conf –i 启动客户端 zabbix_agentd.exe -c D:\\zabbix_agent\\conf\\zabbix_agentd.win.conf –s 创建自动发现规则 配置->自动发现->创建发现规则 添加关联动作 操作-可添加发现主机发送邮件通知 发送模版 默认接收人自动发现主机: {DISCOVERY.DEVICE.STATUS} {DISCOVERY.DEVICE.IPADDRESS} 默认信息 发现规则: {DISCOVERY.RULE.NAME} 设备IP:{DISCOVERY.DEVICE.IPADDRESS} 设备DNS: {DISCOVERY.DEVICE.DNS} 设备状态: {DISCOVERY.DEVICE.STATUS} 设备运行时间: {DISCOVERY.DEVICE.UPTIME} 设备服务端口: {DISCOVERY.SERVICE.NAME} Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-19 13:12:30 "},"linux/MySQL配置主从读写分离.html":{"url":"linux/MySQL配置主从读写分离.html","title":"MySQL配置主从读写分离","keywords":"","body":"mysql配置主从 读写分离 配置主从 一般来说都是通过 主从复制（Master-Slave）的方式来同步数据，再通过读写分离（MySQL-Proxy/Amoeba）来提升数据库的并发负载能力 这样的方案来进行部署与实施的。Replication可以实现将数据从一台数据库服务器（master）复制到一或多台数据库服务器（slave） 默认情况下属于异步复制，无需维持长连接 通过配置，可以复制所有的库或者几个库，甚至库中的一些表 是MySQL内建的，本身自带的 DML:SQL操作语句，update,insert，delete Relay log :中继日志 mysql主从复制过程(一定要理解掌握,面试经常遇到) 第一步：master记录二进制日志。在每个事务更新数据完成之前，master在二进制日志记录这些改变。MySQL将事务写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。 第二步：slave将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经执行完master产生的所有文件，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。 第三步：SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重新执行其中的事件而更新slave的数据，使其与master中的数据一致。 常见方案：一主多从 一般用来做读写分离的，master写，其他slave读，这种架构最大问题I/O压力集中 试验环境： 主服务器 192.168.1.63 Master mysql版本 5.7.20 从服务器 192.168.1.64 slave mysql版本 5.7.20 实验前需要确保两台服务器能够正常访问mysql，mysql服务正常开启 1.配置主数据库服务器 1.1 安装好数据库 1.2修改配置文件 vim /etc/my.cnf 新增加配置： server-id=1 #本机数据库ID标示 log-bin=master-bin #启用二进制日志 innodb-file-per-table=ON #使用独立的表空间,属于优化参数,可以不加 skip-name-resolve=ON #跳过DNS解析,加快连接速度,属于优化参数,可以不加 1.3授权账号，让从数据库服务器有权限连接过来，进行同步数据 mysql> grant replication slave on *.* to 'slave'\\@'192.168.1.%' identified by '123456'; mysql> flush privileges; 重启mysql服务 1.4查看状态信息 mysql> show master status; +-------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-------------------+----------+--------------+------------------+-------------------+ | master-bin.000001 | 154 | | | | +-------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 1.5查看二进制日志 [root\\@lewis63 ~]# ls /var/lib/mysql auto.cnf client-cert.pem ib_logfile0 master-bin.index performance_schema server-key.pem bbs client-key.pem ib_logfile1 mysql private_key.pem sys ca-key.pem ib_buffer_pool ibtmp1 mysql.sock public_key.pem ca.pem ibdata1 master-bin.000001 mysql.sock.lock server-cert.pem mysql> show binlog events\\G 2．配置从数据库 两台数据库服务器mysql版本要一致 并且数据库的数据要保存一致,可以导出数据库将导出的数据库传给从服务器 因为我们这里的数据库都是初始化状态,主从已经是一致了 mysql> show variables like '%version%'; +-------------------------+------------------------------+ | Variable_name | Value | +-------------------------+------------------------------+ | innodb_version | 5.7.20 | | protocol_version | 10 | | slave_type_conversions | | | tls_version | TLSv1,TLSv1.1 | | version | 5.7.20 | | version_comment | MySQL Community Server (GPL) | | version_compile_machine | x86_64 | | version_compile_os | Linux | +-------------------------+------------------------------+ 测试连接到主服务器是否成功 [root\\@lewis64 ~]# mysql -uslave -p123456 -h192.168.1.63 修改从服务器配置文件 vim /etc/my.cnf 增加： server-id=2 relay-log-index=relay-log.index innodb-file-per-table=ON skip-name-resolve=ON 说明： server-id=2 从服务器ID号，不要和主ID相同 ，如果设置多个从服务器，每个从服务器必须有一个唯一的server-id值，必须与主服务器的以及其它从服务器的不相同。可以认为server-id值类似于IP地址：这些ID值能唯一识别复制服务器群集中的每个服务器实例。 重启mysql服务器：[root\\@lewis64 ~]# systemctl restart mysqld.service 配置主从 mysql> change master to master_host='192.168.1.63',master_user='slave',master_password='123456',master_log_file='master-bin.000001',master_log_pos=154; mysql> start slave; #启动slave mysql> show slave status\\G 查看状态 Slave_IO_Running ：一个负责与主机的io通信 Slave_SQL_Running：负责自己的slave mysql进程 注意：如果出现NO则检查防火墙和selinux是否关闭，主从mysql的UUID是否重复。若UUID重复，修改/var/lib/mysql/auto.cnf 再到主服务器上查看状态 在主数据库服务器插入数据测试同步： mysql> create database bbs; mysql> use bbs; mysql> create table T1(id int,name varchar(10)); mysql> insert into T1 values(1,'man'); 从数据库上查看： 3.排错： 如果遇到主从不同步，看一下主从bin-log的位置，然后再同步 在主服务器上看二进制日志事件列表 mysql> show binlog events \\G 从服务器执行MySQL命令下： mysql> stop slave； #先停止slave服务 mysql> change master to master_log_file='mysql-bin-master.000001',master_log_pos=1164; #根据上面主服务器的show master status的结果，进行从服务器的二进制数据库记录回归，达到同步的效果 mysql>slave start; #启动从服务器同步服务 mysql> show slave status\\G; #用show slave status\\G;看一下从服务器的同步情况 Slave_IO_Running: Yes Slave_SQL_Running: Yes 如果都是yes，那代表已经在同步 重启从服务器，再查看状态： 停止从服务器slave stop; 开启从服务器slave start; 排错思路： 1、二进制日志没有开启 2、IPTABLES 没有放开端口 3、对应的主机 IP地址写错了 SQL线程出错 1、主从服务器数据库结构不统一 出错后，数据少，可以手动解决创建插入，再更新slave状态。 注：如果主上误删除了。那么从上也就误删除了。#因此主上要定期做mysqldump备份 mysql读写分离 Mysql作为目前世界上使用最广泛的免费数据库，相信所有从事系统运维的工程师都一定接触过。但在实际的生产环境中，由单台Mysql作为独立的数据库是完全不能满足实际需求的，无论是在安全性，高可用性以及高并发等各个方面。 因此，一般来说都是通过 主从复制（Master-Slave）的方式来同步数据，再通过读写分离（MySQL-Proxy/Amoeba）来提升数据库的并发负载能力 这样的方案来进行部署与实施的。 读写分离工作原理： 基本的原理是让主数据库处理事务性增、改、删操作（INSERT、UPDATE、DELETE），而从数据库处理SELECT查询操作。数据库复制被用来把事务性操作导致的变更同步到集群中的从数据库。 数据内部交换过程： 为什么要读写分离： 面对越来越大的访问压力，单台的服务器的性能成为瓶颈，需要分担负载 1、 主从只负责各自的写和读，极大程度的缓解X锁和S锁争用 2、 从库可配置myisam引擎，提升查询性能以及节约系统开销 3、 增加冗余，提高可用性 实现读写分离的方式： 一般有两种方式实现 (1)应用程序层实现，网站的程序实现 应用程序层实现指的是在应用程序内部及连接器中实现读写分离 优点： A：应用程序内部实现读写分离，安装既可以使用 B：减少一定部署难度 C：访问压力在一定级别以下，性能很好 缺点： A：架构一旦调整，代码要跟着变 B：难以实现高级应用，如自动分库，分表 C：无法适用大型应用场景 (2)中间件层实现 中间件层实现是指在外部中间件程序实现读写分离 常见的中间件程序： 使用oneproxy中间件实现读写分离 服务器配置说明: IP 角色 安装说明 192.168.1.65 读写分离服务器 安装oneproxy 192.168.1.63 MySQL-master MySQL mysql 192.168.1.64 MySQL-slave MySQL mysql 2.先安装好1.63和1.64的MySQL服务,并且做好主从复制 3.oneproxy服务安装和配置 [root\\@lewis65 ~]# wget http://www.onexsoft.com/software/oneproxy-rhel6-linux64-v6.0.0-ga.tar.gz 解压：[root\\@lewis65 ~]# tar xf oneproxy-rhel6-linux64-v6.0.0-ga.tar.gz -C /usr/local/ 修改启动文件中默认读写路径 [root\\@lewis65 ~]# cd /usr/local/oneproxy/ [root\\@lewis65 oneproxy]# ls bin demo.sh oneproxy.service sql testautocommit.sql trantest.sql conf log README testadmin.sql testproxy.sql [root\\@lewis65 oneproxy]# vim oneproxy.service ONEPROXY_HOME=/usr/local/oneproxy #修改默认的家目录的路径,修改成oneproxy的安装目录 复制启动文件到系统启动路径下: [root\\@lewis65 oneproxy]# cp oneproxy.service /etc/init.d 下面就可以通过命令来启动服务了: [root\\@lewis65 oneproxy]# /etc/init.d/oneproxy.service start 启动 [root\\@lewis65 oneproxy]# /etc/init.d/oneproxy.service stop 关闭 [root\\@lewis65 oneproxy]# /etc/init.d/oneproxy.service restart 重启 修改主配置文件,填写读写分离的相关信息: [root\\@lewis65 oneproxy]# cd conf/ [root\\@lewis65 conf]# vim proxy.conf [oneproxy] keepalive = 1 #保持连接 event-threads = 4 #并发连接数，最大允许48个线程。通常可以设为CPU Core数量的两倍 log-file = log/oneproxy.log #日志文件 pid-file = log/oneproxy.pid #进程文件 lck-file = log/oneproxy.lck #锁文件 max-idle-time = 30 #最大空闲时间 admin-address =:4044 #管理服务端口 proxy-address =:3307 #代理服务端口 proxy-socket-file =/tmp/oneproxy.sock #sock文件 mysql-version =5.7.20 #MySQL版本 proxy-license = A2FF461456A67F28,D2F6A5AD70C9042D proxy-httpserver = 0.0.0.0:8080 #管理页面地址 proxy-httptitle = OneProxy Monitor proxy-httpauth =admin:oneproxy #页面登录账号 密码 proxy-auto-readonly = 0 proxy-slave-addresses.1 = 192.168.1.64:3306\\@server1 #从MySQL,server1为服务组名称，任意写 proxy-master-addresses.1 = 192.168.1.63:3306\\@server1 #主MySQL,server1为服务组名称，任意写 proxy-group-policy = server1:read_balance #代理策略,read_balance 为:主MySQL负责写, 主从负载均衡读 proxy-user-list = root/9D7E55EAF8912CCBF32069443FAC452794F8941B\\@bbs #连接后端数据库的账户/密码\\@数据库，这里的密码是加密之后的密码 remote-address.1 = 192.168.1.119:4041 proxy-part-template = conf/template.txt proxy-part-tables = conf/part.txt proxy-sequence-group = default proxy-sequence.1 = seq1 要确保这个账号有权限能连接到后端数据库 分别在主从服务器执行授权命令: mysql>grant all privileges on *.* to 'root\\@'192.168.1.%' identified by ' 123456' with grant option; mysql> flush privileges; #要确保后端数据库有bbs(名字根据实际情况来定)这个库,oneproxy就是靠这个库的存在来判断后端数据库的存活状态 进入oneproxy中的bin目录，使用mysqlpwd对密码进行加密 [root\\@lewis65 bin]# ./mysqlpwd 123456 9D7E55EAF8912CCBF32069443FAC452794F8941B 把得到的这一串字符串写到配置文件里 保存文件,启动服务,测试读写分离 [root\\@lewis65 conf]# /etc/init.d/oneproxy.service start [root\\@lewis65 ~]# netstat -antpu | grep oneproxy tcp 0 0 0.0.0.0:3307 0.0.0.0:* LISTEN 1148/oneproxy tcp 0 0 0.0.0.0:8080 0.0.0.0:* LISTEN 1148/oneproxy tcp 0 0 0.0.0.0:4041 0.0.0.0:* LISTEN 1148/oneproxy 可以通过网页浏览数据库的状态: 通过连接oneProxy代理,测试读写分离(可以用数据库终端工具) 测试读： 测试写： 执行DDL语句提示（）： ERROR 1044 (42000): Access denied due to security policy, DDL disabled or DML restricted! 解释：由于OneProxy为了安全起见，默认是禁止DDL语句的。 解决办法： oneproxy服务器配置文件 [root\\@lewis65 ~]# vim /usr/local/oneproxy/conf/proxy.conf 加入： --proxy-group-security = \\:{0} (2)从OneProxy管理端口，运行如下命令： [root\\@lewis65 ~]# mysql -uadmin -pOneProxy -P4041 -h192.168.1.65 -e \"set gaccess server1 0;\" 测试： 因为主从复制效果可能看不出来，可以先关闭主从，但是生产环境往往不允许这样做 在master或slave或其它任意一台非集群的机器登录代理服务器执行 可以进行DDL语句操作，登录主从数据库查看： 各种读写分离的主要策略简介 master_only：读写都在主服务器上 read_failover:在主服务器正常的情况下，读写都在主库上，如果读失败，才到从库上读 read-slave:主库执行写操作，从库执行读操作 read_other:主服务器负责写，其他节点负责读 read_shard:主服务器负责写，其他节点通过一致性hash到其他节点读 read_iphash:主服务器负责写，其他节点通过IP的hash到其他节点读 read_balance：主服务器负责写，读在主与从之间轮询 write_failover:在一台主服务器写，读在所有主与从服务器上轮询 write_banlance:写在所有主服务器上轮询，写在所有主与从服务器上轮询 write_shard:读写在主和从服务器上通过一致性hash轮询 write_iphash:读写在主和从服务器上通过ip的hash轮询 big_slave：写和简单的读在主服务器上，复杂查询在从上 big_balance:写和简单的读在主服务器上，复杂查询在主和从上轮询 参数补充: 通过bin/oneproxy --help-all可以查看所有配置项 其选项基本上分为oneproxy模块参数(对应的功能)和应用参数 Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-19 13:08:35 "},"linux/MySQL高可用之MHA.html":{"url":"linux/MySQL高可用之MHA.html","title":"MySQL高可用之MHA","keywords":"","body":"MySQL高可用之MHA MHA简介 1.MHA介绍 MHA（Master High Availability）目前在MySQL高可用方面是一个相对成熟的解决方案，它由日本DeNA公司youshimaton（现就职于Facebook公司）开发，是一套优秀的作为MySQL高可用性环境下故障切换和主从提升的高可用软件。在MySQL故障切换过程中，MHA能做到在0~30秒之内自动完成数据库的故障切换操作，并且在进行故障切换的过程中，MHA能在最大程度上保证数据的一致性，以达到真正意义上的高可用。 该软件由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）。MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。 在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。 目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因为至少需要三台服务器，出于机器成本的考虑，淘宝也在该基础上进行了改造，目前淘宝TMHA已经支持一主一从。 2.MHA工作原理 （1）从宕机崩溃的master保存二进制日志事件（binlog events）; （2）识别含有最新更新的slave； （3）应用差异的中继日志（relay log）到其他的slave； （4）应用从master保存的二进制日志事件（binlog events）； （5）提升一个slave为新的master； （6）使其他的slave连接新的master进行复制； 3.MHA软件组成 MHA软件由两部分组成，Manager工具包和Node工具包，具体的说明如下。 Manager工具包主要包括以下几个工具： masterha_check_ssh 检查MHA的SSH配置状况 masterha_check_repl 检查MySQL复制状况 masterha_manger 启动MHA masterha_check_status 检测当前MHA运行状态 masterha_master_monitor 检测master是否宕机 masterha_master_switch 控制故障转移（自动或者手动） masterha_conf_host 添加或删除配置的server信息 Node工具包（这些工具通常由MHA Manager的脚本触发，无需人为操作）主要包括以下几个工具： save_binary_logs 保存和复制master的二进制日志 apply_diff_relay_logs 识别差异的中继日志事件并将其差异的事件应用于其他的slave filter_mysqlbinlog 去除不必要的ROLLBACK事件（MHA已不再使用这个工具） purge_relay_logs 清除中继日志（不会阻塞SQL线程） MySql半同步复制 2.1复制的分类及区别 异步复制：MySQL复制默认是异步复制。主库将事务Binlog事件写入到Binlog文件中，此时主库只会通知一下Dump线程发送这些新的Binlog，但并不知道Slave是否或何时已经接收且已处理。然后主库就会继续处理提交操作，而此时不会保证这些Binlog传到任何一个从库节点上。在异步复制的机制的情况下，如果Master宕机，事务在Master上已提交，但很可能这些事务没有传到任何的Slave上，此时Slave也可能会丢失事务 全同步复制：MySQL在5.7.17中引入了一个全新的技术。当主库提交事务之后，所有的从库节点必须收到，APPLY并且提交这些事务，然后主库线程才能继续做后续操作。这里面有一个很明显的缺点就是，主库完成一个事务的时间被拉长，性能降低。 半同步复制：介于全同步复制和异步复制之间的一种。主库只需要等待至少一个从库节点收到并且Flush Binlog到Relay Log文件即可，主库不需要等待所有从库给主库反馈。同时，这里只是一个收到的反馈，而不是已经完全执行并且提交的反馈，这样就节省了很多时间。一定程度上保证提交的事务已经传给了至少一个备库。 实验拓扑 具体搭建环境（使用操作系统为Centos7.4）： 主机名 IP 角色 软件 lewis63 192.168.1.63 manager,Master mha4mysql-manager、mha4mysql-node lewis64 192.168.1.64 Slave1,Candicate master mha4mysql-node keepalived lewis65 192.168.1.65 slave2 mha4mysql-node keepalived 其中master对外提供写服务，备选Candicate master（实际为slave1）提供读服务，slave2也提供读服务，一旦master宕机，将会把备选master提升为新的master，slave指向新的master。三台服务器都安装mysql5.7 前提准备（三台机器） 4.1配置hosts cat /etc/hosts 192.168.1.63 lewis63 192.168.1.64 lewis64 192.168.1.65 lewis65 4.2配置ssh免密码登录 配置所有主机相互SSH登录无密码验证（使用key登录，工作中常用）。 注意：不能禁止 password 登陆，否则会出现错误 [root\\@lewis63 ~]# ssh-keygen 一路回车 。。。 [root\\@lewis63 ~]# ssh-copy-id 192.168.1.63 [root\\@lewis63 ~]# ssh-copy-id 192.168.1.64 [root\\@lewis63 ~]# ssh-copy-id 192.168.1.65 其他主机重复上面操作 测试： 在任意一台ssh到另外机器 搭建主从复制环境 5.1配置主数据库服务器 在lewis63创建需要同步的数据库 [root\\@lewis63 ~]# mysql -uroot -p mysql> create database HA; mysql> use HA; mysql> create table test(id int,name varchar(20)); [root\\@lewis63 ~]# vim /etc/my.cnf log-bin=mysql-bin-master server-id=1 binlog-do-db=HA binlog-ignore-db=mysql [root\\@lewis63 ~]# systemctl restart mysqld #重启mysql 授权： mysql> grant replication slave on *.* to repl\\@'192.168.1.%' identified by '123456'; mysql> flush privileges; mysql> show master status; +-------------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-------------------------+----------+--------------+------------------+-------------------+ | mysql-bin-master.000001 | 599 | HA | mysql | | +-------------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 导出数据库到从数据库服务器 [root\\@lewis63 ~]# mysqldump -uroot -p123456 -B HA > HA.sql [root\\@lewis63 ~]# scp HA.sql 192.168.1.64:/root [root\\@lewis63 ~]# scp HA.sql 192.168.1.65:/root 5.2配置lewis64数据库服务器 导入数据库： mysql -uroot -p123456 \\ 配置my.cnf [root\\@lewis64 ~]# vim /etc/my.cnf [mysqld]加入 ……. log-bin=mysql-bin-slave1 server-id=2 binlog-do-db=HA binlog-ignore-db=mysql log_slave_updates=1 [root\\@lewis64 ~]# systemctl restart mysqld mysql> grant replication slave on *.* to 'repl'\\@'192.169.1.%' identified by '123456'; mysql> flush privileges; 建立主从关系： mysql> change master to master_host='192.168.1.63',master_user='repl',master_password='123456',master_log_file='mysql-bin-master.000001',master_log_pos=599; mysql> start slave; 从服务器设置read_only: 注意：两台slave服务器设置read_only（从库对外提供读服务，之所以没有写进配置文件，是因为slave随时会提升为master） [root\\@lewis64 ~]# mysql -uroot -p123456 -e 'set global read_only=1' mysql> start slave; #启动slave mysql> show slave status\\G #查看状态 5.3配置lewis65从数据库服务器 导入数据库： mysql -uroot -p123456 \\ 配置my.cnf [root\\@lewis64 ~]# vim /etc/my.cnf [mysqld]加入 ……. log-bin=mysql-bin-slave2 server-id=3 binlog-do-db=HA binlog-ignore-db=mysql log_slave_updates=1 [root\\@lewis65 ~]# systemctl restart mysqld mysql> grant replication slave on *.* to 'repl'\\@'192.169.1.%' identified by '123456'; mysql> flush privileges; 建立主从关系： mysql> change master to master_host='192.168.1.63',master_user='repl',master_password='123456',master_log_file='mysql-bin-master.000001',master_log_pos=599; mysql> start slave; 从服务器设置read_only: 注意：两台slave服务器设置read_only（从库对外提供读服务，之所以没有写进配置文件，是因为slave随时会提升为master） [root\\@lewis65 ~]# mysql -uroot -p123456 -e 'set global read_only=1' mysql> start slave; #启动slave mysql> show slave status\\G #查看状态 5.4在Master创建监控用户 mysql> grant all privileges on *.* to 'root'\\@'192.168.1.%' identified by '123456'; mysql> flush privileges; MySQL5.7 半同步复制搭建 半同步复制的功能要在Master，Slave都开启，半同步复制才会起作用；否则，只开启一边，它依然为异步复制。 6.1 Master配置 在192.168.1.63配置： 安装半同步模块并启动(此模块位于/usr/local/mysql/lib/plugin/semisync_master.so) mysql> install plugin rpl_semi_sync_master soname 'semisync_master.so'; mysql> show global variables like 'plugin_dir'; +---------------+--------------------------+ | Variable_name | Value | +---------------+--------------------------+ | plugin_dir | /usr/lib64/mysql/plugin/ | +---------------+--------------------------+ 查看是否启用： rpl_semi_sync_master_wait_point | AFTER_SYNC 5.7引入了无损复制（after_sync）模式，带来的主要收益是解决after_commit导致的master crash后数据丢失问题，因此在引入after_sync模式后，所有提交的数据已经都被复制，故障切换时数据一致性将得到提升。 临时启用半同步： mysql> set global rpl_semi_sync_master_enabled = 1; mysql> set global rpl_semi_sync_master_timeout = 2000; 安装后启动和定制主从连接错误的超时时间默认是10s可改为2s，一旦有一次超时自动降级为异步 永久启用半同步复制： [root\\@lewis63 ~]# vim /etc/my.cnf [mysqld] … rpl_semi_sync_master_enabled=1 rpl_semi_sync_master_timeout=2000 扩展： 卸载模块：mysql> uninstall plugin rpl_semi_sync_master; 6.2 Slave配置 192.168.1.64和192.168.1.65安装半同步模块并启动 mysql> install plugin rpl_semi_sync_slave soname 'semisync_slave.so'; mysql> set global rpl_semi_sync_slave_enabled = 1; 查看是否启用 mysql> show global variables like '%semi%'; vim /etc/my.cnf [mysqld] …… rpl_semi_sync_slave_enabled=1 6.3从节点需要重新连接主服务器半同步才会生效 mysql> stop slave io_thread; mysql> start slave io_thread; 6.4 Master节点查看是否启用半同步 主要看Rpl_semi_sync_master_clients是否不为0，Rpl_semi_sync_master_status是否为ON。如果Rpl_semi_sync_master_status为OFF，说明出现了网络延迟或Slave IO线程延迟。 搭建MHA 7.1安装MHA Node 所有节点安装mysql-community-libs-compat rpm -ivh mysql-community-libs-compat-5.7.20-1.el7.x86_64.rpm 在所有节点安装MHA node所需的全部依赖 yum -y install perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-Parallel-ForkManager --skip-broken 方法一：rpm包安装 上传MHA相关包，在所有的节点安装mha-node rpm -ivh mha4mysql-node-0.53-0.el6.noarch.rpm 安装完成会在/usr/bin/目录下生成以下脚本文件： [root\\@lewis63 bin]# ll app* filter* purge* save* -rwxr-xr-x 1 root root 15498 Jan 8 2012 apply_diff_relay_logs -rwxr-xr-x. 1 root root 46256 Jun 10 2014 filterdiff -rwxr-xr-x 1 root root 4807 Jan 8 2012 filter_mysqlbinlog -rwxr-xr-x 1 root root 7401 Jan 8 2012 purge_relay_logs -rwxr-xr-x 1 root root 7263 Jan 8 2012 save_binary_logs 方法二：源码安装 tar -zxf mha4mysql-node-0.56.tar.gz -C /usr/local/src/ cd !$ cd mha4mysql-node-0.56/ perl Makefile.PL 可能报错： Can't locate ExtUtils/MakeMaker.pm 解决： yum -y install perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker cpan make -j 2 && make install 7.2安装MHA Manager MHA Manager中主要包括了几个管理员的命令行工具，例如master_manger，master_master_switch等。MHA Manger也依赖于perl模块。MHA Manager可单独安装在一台服务器，这里的架构是安装在lewis63 Master主数据库服务器 需要先配置epel源，前面已经安装 安装MHA Manger依赖的perl模块： yum install perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker perl-CPAN –y 方法一：rpm包安装 安装MHA Manager软件包： [root\\@lewis63 ~]# rpm -ivh mha4mysql-manager-0.53-0.el6.noarch.rpm 安装完成后会在/usr/bin目录下面生成以下脚本文件 [root\\@lewis63 ~]# ll /usr/bin/master* -rwxr-xr-x 1 root root 1995 Jan 8 2012 /usr/bin/masterha_check_repl -rwxr-xr-x 1 root root 1779 Jan 8 2012 /usr/bin/masterha_check_ssh -rwxr-xr-x 1 root root 1865 Jan 8 2012 /usr/bin/masterha_check_status -rwxr-xr-x 1 root root 3201 Jan 8 2012 /usr/bin/masterha_conf_host -rwxr-xr-x 1 root root 2517 Jan 8 2012 /usr/bin/masterha_manager -rwxr-xr-x 1 root root 2165 Jan 8 2012 /usr/bin/masterha_master_monitor -rwxr-xr-x 1 root root 2373 Jan 8 2012 /usr/bin/masterha_master_switch -rwxr-xr-x 1 root root 3749 Jan 8 2012 /usr/bin/masterha_secondary_check -rwxr-xr-x 1 root root 1739 Jan 8 2012 /usr/bin/masterha_stop 方法二：源码安装 [root\\@lewis63 ~]# tar -zxf mha4mysql-manager-0.56.tar.gz [root\\@lewis63 ~]# cd mha4mysql-manager-0.56 [root\\@lewis63 mha4mysql-manager-0.56]# perl Makefile.PL [root\\@lewis63 mha4mysql-manager-0.56]# make -j 2 && make install [root\\@lewis63 ~]# mkdir -p /etc/masterha [root\\@lewis63 ~]# cd mha4mysql-manager-0.56 [root\\@lewis63 mha4mysql-manager-0.56]# cp samples/conf/* /etc/masterha/ [root\\@lewis63 mha4mysql-manager-0.56]# cp samples/scripts/* /usr/local/bin/ [root\\@lewis63 ~]# vim /etc/masterha/app1.cnf [server default] manager_workdir=/var/log/masterha/app1 manager_log=/var/log/masterha/app1/manager.log master_binlog_dir=/var/lib/mysql #master_ip_failover_script= /usr/local/bin/master_ip_failover master_ip_online_change_script= /usr/local/bin/master_ip_online_change password=123456 user=root ping_interval=1 remote_workdir=/tmp repl_password=123456 repl_user=repl report_script=/usr/local/send_report shutdown_script=\"\" ssh_user=root [server1] hostname=192.168.1.63 port=3306 [server2] hostname=192.168.1.64 port=3306 candidate_master=1 [server3] hostname=192.168.1.65 port=3306 说明： [server default] manager_workdir=/var/log/masterha/app1 //设置manager的工作目录 manager_log=/var/log/masterha/app1/manager.log //设置manager的日志 master_binlog_dir=/data/mysql //设置master 保存binlog的位置，以便MHA可以找到master的日志，我这里的也就是mysql的数据目录 master_ip_failover_script= /usr/local/bin/master_ip_failover //设置自动failover时候的切换脚本, Failover两种方式：一种是虚拟IP地址，一种是全局配置文件。MHA并没有限定使用哪一种方式，而是让用户自己选择，虚拟IP地址的方式会牵扯到其它的软件,比如keepalive软件，需要修改脚本master_ip_failover。这里先注释，否则后面检测复制环境会不通过 master_ip_online_change_script= /usr/local/bin/master_ip_online_change //设置手动切换时候的切换脚本 password=123456 //设置mysql中root用户的密码，这个密码是前文中创建监控用户的那个密码 user=root 设置监控用户root ping_interval=1 //设置监控主库，发送ping包的时间间隔，默认是3秒，尝试三次没有回应的时候自动进行railover remote_workdir=/tmp //设置远端mysql在发生切换时binlog的保存位置 repl_password=123456 //设置复制用户的密码 repl_user=repl //设置复制环境中的复制用户名 report_script=/usr/local/send_report //设置发生切换后发送的报警的脚本 shutdown_script=\"\" //设置故障发生后关闭故障主机脚本（该脚本的主要作用是关闭主机放在发生脑裂,这里没有使用） ssh_user=root //设置ssh的登录用户名 candidate_master=1 //设置为候选master，如果设置该参数以后，发生主从切换以后将会将此从库提升为主库，即使这个主库不是集群中事件最新的slave check_repl_delay=0 //默认情况下如果一个slave落后master 100M的relay logs的话，MHA将不会选择该slave作为一个新的master，因为对于这个slave的恢复需要花费很长时间，通过设置check_repl_delay=0,MHA触发切换在选择一个新的master的时候将会忽略复制延时，这个参数对于设置了candidate_master=1的主机非常有用，因为这个候选主在切换的过程中一定是新的master 7.3设置relay log的清除方式(在每个slave节点上) [root\\@lewis64 ~]# mysql -uroot -p123456 -e 'set global relay_log_purge=0' [root\\@lewis65 ~]# mysql -uroot -p123456 -e 'set global relay_log_purge=0' 注意： MHA在发生切换的过程中，从库的恢复过程中依赖于relay log的相关信息，所以这里要将relay log的自动清除设置为OFF，采用手动清除relay log的方式。在默认情况下，从服务器上的中继日志会在SQL线程执行完毕后被自动删除。但是在MHA环境中，这些中继日志在恢复其他从服务器时可能会被用到，因此需要禁用中继日志的自动删除功能。定期清除中继日志需要考虑到复制延时的问题。在ext3的文件系统下，删除大的文件需要一定的时间，会导致严重的复制延时。为了避免复制延时，需要暂时为中继日志创建硬链接，因为在Linux系统中通过硬链接删除大文件速度会很快。（在mysql数据库中，删除大表时，通常也采用建立硬链接的方式） 7.4检查SSH配置 [root\\@lewis63 ~]# masterha_check_ssh --conf=/etc/masterha/app1.cnf 7.5检查整个复制环境状况 #master_ip_failover_script= /usr/local/bin/master_ip_failover #配置文件把这行先注释 [root\\@lewis63 ~]# masterha_check_repl --conf=/etc/masterha/app1.cnf 7.6检查MHA Manager的状态 [root\\@lewis63 ~]# masterha_check_status --conf=/etc/masterha/app1.cnf app1 is stopped(2:NOT_RUNNING). 注意：如果正常，会显示\"PING_OK\"，否则会显示\"NOT_RUNNING\"，这代表MHA监控没有开启。 7.7开启MHA Manager监控 [root\\@lewis63 ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover \\ /var/log/masterha/app1/manager.log 2>&1 & [1] 2318 启动参数介绍： --remove_dead_master_conf 该参数代表当发生主从切换后，老的主库的ip将会从配置文件中移除。 --manger_log 日志存放位置 --ignore_last_failover 在缺省情况下，如果MHA检测到连续发生宕机，且两次宕机间隔不足8小时的话，则不会进行Failover，之所以这样限制是为了避免ping-pong效应。该参数代表忽略上次MHA触发切换产生的文件，默认情况下，MHA发生切换后会在日志目录，也就是上面我设置的/data产生app1.failover.complete文件，下次再次切换的时候如果发现该目录下存在该文件将不允许触发切换，除非在第一次切换后收到删除该文件，为了方便，这里设置为--ignore_last_failover。 查看MHA Manager监控是否正常： [root\\@lewis63 ~]# masterha_check_status --conf=/etc/masterha/app1.cnf app1 (pid:2318) is running(0:PING_OK), master:192.168.1.63 7.8查看启动日志 [root\\@lewis63 ~]# tail -n20 /var/log/masterha/app1/manager.log …… Mon Sep 24 17:06:15 2018 - [info] Starting ping health check on 192.168.1.63(192.168.1.63:3306).. Mon Sep 24 17:06:15 2018 - [info] Ping(SELECT) succeeded, waiting until MySQL doesn't respond.. 代表整个系统已经开始监控了。 7.9关闭MHA Manage监控 关闭使用masterha_stop命令完成 masterha_stop --conf=/etc/masterha/app1.cnf 模拟故障 [root\\@lewis63 ~]# systemctl stop mysqld #模拟主库挂掉 [root\\@lewis63 ~]# tail -f /var/log/masterha/app1/manager.log #开启新窗口查看日志 ----- Failover Report ----- app1: MySQL Master failover 192.168.1.63(192.168.1.63:3306) to 192.168.1.64(192.168.1.64:3306) succeeded Master 192.168.1.63(192.168.1.63:3306) is down! Check MHA Manager logs at lewis63:/var/log/masterha/app1/manager.log for details. Started automated(non-interactive) failover. The latest slave 192.168.1.64(192.168.1.64:3306) has all relay logs for recovery. Selected 192.168.1.64(192.168.1.64:3306) as a new master. 192.168.1.64(192.168.1.64:3306): OK: Applying all logs succeeded. 192.168.1.65(192.168.1.65:3306): This host has the latest relay log events. Generating relay diff files from the latest slave succeeded. 192.168.1.65(192.168.1.65:3306): OK: Applying all logs succeeded. Slave started, replicating from 192.168.1.64(192.168.1.64:3306) 192.168.1.64(192.168.1.64:3306): Resetting slave info succeeded. Master failover to 192.168.1.64(192.168.1.64:3306) completed successfully. Mon Sep 24 20:07:23 2018 - [info] Sending mail.. sh: /usr/local/send_report: No such file or directory Mon Sep 24 20:07:23 2018 - [error][/usr/local/share/perl5/MHA/MasterFailover.pm, ln2065] Failed to send mail with return code 127:0 在lewis65检查： mysql> show slave status\\G; 从日志上可以看到故障切换成功，新的master是lewis64 Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-25 10:13:52 "},"linux/GitLab与Jenkins结合构建持续集成环境.html":{"url":"linux/GitLab与Jenkins结合构建持续集成环境.html","title":"GitLab与Jenkins结合构建持续集成(CI)环境","keywords":"","body":"GitLab与Jenkins结合构建持续集成(CI)环境 一．持续集成概述及gitlab介绍 1.持续集成概述及运行流程： 持续集成概述：持续集成（Continuous integration）持续集成是指开发者在代码的开发过程中，可以频繁的将代码部署集成到主干，并进程自动化测试。 持续交付：持续交付指的是在持续集成的环境基础之上，将代码部署到预生产环境。 持续部署：在持续交付的基础上，把部署到生产环境的过程自动化。 2.GitHub和GitLab的区别： 相同点: 二者都是基于web的Git仓库，在很大程度上GitLab是仿照GitHub来做的，它们都提供了分享开源项目的平台，为开发团队提供了存储、分享、发布和合作开发项目的中心化云存储的场所。 不同点： 1、GitHub如果要使用私有仓库，是需要付费的。GitLab可以在上面创建私人的免费仓库。 2、GitLab让开发团队对他们的代码仓库拥有更多的控制，相比于GitHub，它有不少的特色：允许免费设置仓库权限；允许用户选择分享一个project的部分代码；允许用户设置project的获取权限，进一步的提升安全性；可以设置获取到团队整体的改进进度；通过innersourcing让不在权限范围内的人访问不到该资源。 总结：从代码私有性方面来看，有时公司并不希望员工获取到全部的代码，这个时候GitLab无疑是更好的选择。但对于开源项目而言，GitHub依然是代码托管的首选。 github 是一个基于git实现的在线代码托管仓库，包含一个网站界面，向互联网开放 gitlab 是一个基于git实现的在线代码仓库托管软件，一般用于在企业内部网络搭建git私服 注： gitlab-ce 社区版 ； gitlab-ee是企业版，收费 3.持续集成系统的工作流程大概分为以下几步 1, 开发者将新版本push到Gitlab。 2, Gitlab随后触发jenkins master结点进行一次build。(通过web hook或者定时检测) 3, jenkins master结点将这个build任务分配给若干个注册的slave结点中的一个，这个slave结点根据一个事先设置好的脚本进行build。这个脚本可以做的事情很多，比如编译，测试，生成测试报告等等。这些原本需要手动完成的任务都可以交给jenkins来做。 4, 我们在build中要进行编译，这里使用了分布式编译器distcc来加快编译速度。 二．搭建GitLab平台 实验环境： centos7.4 虚拟机需要6G，不然后期运行时，内存不够用，直接报错。 安装Gitlab需要的组件 yum install curl policycoreutils openssh-server openssh-clients postfix -y 默认，使用 Postfix 发送邮件 systemctl start postfix;systemctl enable postfix iptables –F systemctl stop firewalld;systemctl disable firewalld 安装GitLab 方法一：使用清华源yum安装 [root\\@lewis63 yum.repos.d]# cat gitlab_gitlab-ce.repo [gitlab-ce] name=gitlab-ce baseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7 repo_gpgcheck=0 gpgcheck=0 enabled=1 gpgkey=https://packages.gitlab.com/gpg.key [root\\@lewis63 ~]# yum install gitlab-ce –y 方法二：本地上rpm包安装 [root\\@lewis63 ~]# rpm -ivh gitlab-ce-10.2.3-ce.0.el7.x86_64.rpm 安装完成有提示让配置gitlab访问地址： [root\\@lewis63 ~]# vim /etc/gitlab/gitlab.rb external_url 'http://192.168.1.63' #修改成自己IP地址 重新配置应用程序 gitlab-ctl reconfigure #重新配置应用程序。修改了gitlab服务配置文件后，都需要执行一下这个命令。让各个服务的配置文件，重新加载一下配置文件。 [root\\@lewis63 ~]# gitlab-ctl status #可以使用gitlab-ctl管理gitlab，例如查看gitlab状态： run: gitaly: (pid 3404) 79s; run: log: (pid 3106) 126s run: gitlab-monitor: (pid 3420) 78s; run: log: (pid 3169) 114s run: gitlab-workhorse: (pid 3392) 80s; run: log: (pid 3062) 139s run: logrotate: (pid 3090) 132s; run: log: (pid 3089) 132s run: nginx: (pid 3069) 138s; run: log: (pid 3068) 138s run: node-exporter: (pid 3154) 120s; run: log: (pid 3153) 120s run: postgres-exporter: (pid 3446) 77s; run: log: (pid 3317) 96s run: postgresql: (pid 2841) 198s; run: log: (pid 2840) 198s run: prometheus: (pid 3436) 78s; run: log: (pid 3249) 102s run: redis: (pid 2781) 209s; run: log: (pid 2780) 209s run: redis-exporter: (pid 3222) 108s; run: log: (pid 3221) 108s run: sidekiq: (pid 3045) 146s; run: log: (pid 3044) 146s run: unicorn: (pid 3007) 152s; run: log: (pid 3006) 152s [root\\@lewis63 ~]# netstat -anput | grep 80 tcp 0 0 127.0.0.1:8080 0.0.0.0:* LISTEN 3040/unicorn master tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 3069/nginx: master tcp 0 0 0.0.0.0:8060 0.0.0.0:* LISTEN 3069/nginx: master 默认使用nginx做为web界面 注：如果后期web界面访问时，总报502，要把防火墙清空规则，另外内存要大于4G，不然后内存不足，也报502 登录GitLab 第一次登录gitlab，需要为root用户修改密码，root用户也是gitlab的超级管理员 关闭GitLab注册功能： 默认情况下可以直接注册账号，不需要注册功能，可以关闭。 点Admin area -》 setting -》 取消sign-up enabled标签前对勾 管理GitLab 关闭gitlab： # gitlab-ctl stop 启动gitlab： # gitlab-ctl start 重启gitlab： # gitlab-ctl restart gitlab主配置文件：/etc/gitlab/gitlab.rb //可以自定义一些邮件服务等 日志地址：/var/log/gitlab/ // 对应各服务 服务地址：/var/opt/gitlab/ // 对应各服务的主目录 仓库地址：/var/opt/gitlab/git-data //记录项目仓库等提交信息 重置配置：gitlab-ctl reconfigure //不要乱用，会重置为最原始的配置 重启服务：gitlab-ctl stop/start/restart //启动命令 centos7部署汉化版GitLab 获取gitlab汉化包 下载git：yum install -y git 克隆获取汉化版本库 下载最新的汉化包： git clone https://gitlab.com/xhang/gitlab.git 如果下载老版本的汉化包，需要加上老版本的分支： [root\\@lewis63 ~]# git clone https://gitlab.com/xhang/gitlab.git -b v10.2.3-zh 查看该汉化补丁的版本 cat gitlab/VERSION gitlab-ctl stop #停止gitlab服务 cd /root/gitlab #切换到gitlab汉化包所在的目录 比较汉化标签和原标签，导出 patch 用的 diff 文件到/root下 git diff v10.2.3 v10.2.3-zh > ../10.2.3-zh.diff yum install patch -y cd #回到root 将10.2.3-zh.diff作为补丁更新到gitlab中 patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 \\ 启动服务，等1分钟，再去访问web页面。访问太快会显示502错误。 gitlab-ctl start 三．GitLab日常使用 1.新建项目 先创建群组 创建项目 可见等级： Private：私有的，只有自己或者组内成员可以访问 Internet：所有登录gitlab平台的用户都可以访问 Public：公开的，所有人都可以访问，即不登录gitlab也可以访问 2.创建用户 3.重置用户密码 方法1.登录邮箱 方法2.修改密码 选择Admin area -》用户-》选中用户-》编辑 4.删除用户 当对方离职时候，为了安全起见，需要删除对方的gitlab权限，避免机密信息丢失，操作方法如下： 5.添加用户到群组 6.添加代码 导出克隆项目 安装git yum install git -y 下载项目 [root\\@lewis63 ~]# git clone git\\@192.168.1.63:root/cloudmaster.git 也可以使用http协议下载 [root\\@lewis63 ~]# git clone http://192.168.1.63/root/cloudmaster.git Cloning into 'cloudmaster'... Username for 'http://192.168.1.63': liukai Password for 'http://liukai\\@192.168.1.63':密码 查看克隆下来的代码 [root\\@lewis63 ~]# ls cloudmaster/ -a . .. .git index.html 8.初次运行Git前配置 一般在新的系统上，我们都需要先配置下自己的 Git 工作环境。配置工作只需一次，以后升级时还会沿用现在的配置。 第一个要配置的是你个人的用户名称和电子邮件地址。这两条配置很重要，每次 Git 提交时都会引用这两条信息，说明是谁提交了更新，所以会随更新内容一起被永久纳入历史记录。 git运行的环境变量有点像.bashrc，决定了 Git 在各个环节的具体工作方式和行为。这些变量可以存放在以下两个的地方： 1、~/.gitconfig 文件：用户目录下的配置文件只适用于该用户。若使用 git config 时用 --global 选项，读写的就是这个文件。 例子：修改用户信息 [root\\@lewis63 ~]# git config --global user.name \"liukai\" [root\\@lewis63 ~]# git config --global user.email \"xiaokai0312\\@163.com\" [root\\@lewis63 ~]# cat ~/.gitconfig [user] name = liukai email = xiaokai0312@163.com 2、当前项目的 Git 目录中的配置文件（也就是工作目录中的 .git/config 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所以 .git/config 里的配置会覆盖 ~/.gitconfig中的同名变量。 如果要在某个特定的项目中使用其他名字或者邮件地址，先进到项目上下，然后只要去掉 --global 选项重新配置即可。 最后配置的用户和邮件地址会保存在当前项目的 .git/config 文件里。 例：修改某个git项目下的环境变量 [root\\@lewis63 ~]# cd cloudmaster/ [root\\@lewis63 cloudmaster]# git config user.name \"liukai\" [root\\@lewis63 cloudmaster]# git config user.email \"xiaokai0312\\@163.com\" [root\\@lewis63 cloudmaster]# cat ./.git/config [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \"origin\"] url = http://192.168.1.63/root/cloudmaster.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \"master\"] remote = origin merge = refs/heads/master [user] name = liukai email = xiaokai0312@163.com 9.Git常用命令 git config --global user.name “name“ #设置全局用户名 git config --global user.email mail #设置全局邮箱 git config --global --list #列出用户全局设置 git add index.html #添加文件到暂存区 git commit -m “描述内容“ #提交文件到工作区 git status #查看工作区的状态 git push #提交代码到git服务器上 git pull #获取代码到本地 git log #查看操作日志 vim .gitignore #定义忽略文件 git reset --hard HEAD\\^ #git版本回滚， HEAD为当前版本，加一个\\^为上一个，\\^\\^为上上一个版本 git reflog # #获取每次提交的ID，可以使用--hard根据提交的ID进行版本回退 git reset --hard 5ae4b06 #回退到指定id的版本 # git branch #查看当前所处的分支 git checkout -- file #从服务器更新某个那文件覆盖本地的文件 例：把修改过的index.html文件更新主版本中 [root\\@lewis63 cloudmaster]# echo \"hello,world\" > index.html [root\\@lewis63 cloudmaster]# git add index.html [root\\@lewis63 cloudmaster]# git commit -m \"edit index\" #提交到暂存区中 [master de8e096] edit index 1 file changed, 1 insertion(+), 1 deletion(-) [root\\@lewis63 cloudmaster]# git push -u origin master #上传到主干master上 Username for 'http://192.168.1.63': liukai Password for 'http://liukai\\@192.168.1.63': remote: GitLab: You are not allowed to push code to protected branches on this project. 提示没有权限提交代码到master 解决： 版本库-》保护分支-》允许push选择开发 10.工作区和暂存区及分支 1、工作区就是编辑文件的目录区域，需要将工作区的修改好的文件add到暂存区才能提交到git服务器，在工作区有多个文件的时候可以将一个或多个文件添加至暂存区，再提交到git服务器即可。 2、在服务器创建分支 [root\\@lewis63 cloudmaster]# git branch bbs #创建一个分支 [root\\@lewis63 cloudmaster]# git checkout bbs #切换到分支bbs Switched to branch 'bbs' [root\\@lewis63 cloudmaster]# git branch #查看当前所处的分支 * bbs master [root\\@lewis63 cloudmaster]# echo \"bbs branch\" > a.txt #随意在里面写一些内容 [root\\@lewis63 cloudmaster]# git add a.txt [root\\@lewis63 cloudmaster]# git commit -m \"提交到bbs分支\" #提交到暂存区中 [bbs 0ee53ea] 提交到bbs分支 1 file changed, 1 insertion(+) create mode 100644 a.txt [root\\@lewis63 cloudmaster]# git push -u origin bbs #上传到分支bbs分支上 11.部署密钥 项目-》设置-》版本库 [root\\@lewis63 ~]# ssh-keygen #生成公钥 [root\\@lewis63 ~]# cat .ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDjpJQYgBrwR2WpaR4sr9ENrmrTrSurVcgA0NVuqLHm4HOLrRX9yp+YZGz/65E8vGDRnlgSmUq9CzioCS/dmAHLy7vEZGDh4kz2EbR22p2VfsPJ08bBTdW3ZZ43flqFj/MN3+mnzUWt1PL2CG/VU+eukr5zAjKfXlI3ZQnfG8sp8VxK57+IjEVg4mEOGEbrZrvQjGxuUvf2m8ffgGyWGvzPlc/w5yMG2LtOYXoqPfZ2hWBq8c2ISEhLmDRGUA3fxMUKR62MeYAMa4eVwxeK5dYLVcZBQqLwzLmCD3l/33GNfyPZKvtocor66ma1Qg/KkUbz2CRtMJgrO0l5e2ZnqUT5 root\\@lewis63 把密钥粘贴到gitlab密钥，允许推送，添加密钥 部署key后，可以不用用户密码直接获取代码 12.关于git push.default设置的知识。 默认配置下，当使用git push命令而没有明确的指名本地分支和远程参考分支的情况下，会有如上的提示。如果git push命令没有明确指定引用规格(refspec),也就是没有指定推送的源分支和目标分支，那么git会采用push.default定义的动作。不同的值适用于不同的工作流程模式。 显而易见，主要是因为之前没有进行设置引用规格才出现的这种问题，现在我把push.default的可用值与配置方法贴在下面。push.default可用的值如下： 1.nothing 不推送任何东西并有错误提示，除非明确指定分支引用规格。强制使用分支引用规格来避免可能潜在的错误。 2.current 推送当前分支到接收端名字相同的分支。 3.upstream 推送当前分支到上游\\@{upstream}。这个模式只适用于推送到与拉取数据相同的仓库，比如中央工作仓库流程模式。 4.simple 在中央仓库工作流程模式下，拒绝推送到上游与本地分支名字不同的分支。也就是只有本地分支名和上游分支名字一致才可以推送， 就算是推送到不是拉取数据的远程仓库，只要名字相同也是可以的。在GIT 2.0中，simple将会是push.default的默认值。 simple只会推送本地当前分支。 5.matching 推送本地仓库和远程仓库所有名字相同的分支。这是git当前版本的缺省值。 配置push.default的命令如下： git config --global push.default simple 四．搭建Jenkins实现持续集成 1.源码安装JDK1.8 Jenkins是Java编写的，所以需要先安装JDK，这里采用yum安装，如果对版本有需求，可以直接在Oracle官网下载JDK。 [root\\@lewis63 ~]# tar -zxf jdk-8u161-linux-x64.tar.gz -C /usr/local/ [root\\@lewis63 ~]# cd /usr/local/ [root\\@lewis63 local]# mv jdk1.8.0_161 jdk 配置环境变量 [root\\@lewis63 local]# vim /etc/profile #在末尾加入 export JAVA_HOME=/usr/local/jdk export JRE_HOME=/usr/local/jdk/jre export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH [root\\@lewis63 local]# source /etc/profile #使立即生效 [root\\@lewis63 local]# java -version java version \"1.8.0_161\" Java(TM) SE Runtime Environment (build 1.8.0_161-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 2.安装jenkins [root\\@lewis63 ~]# wget http://pkg.jenkins.io/redhat/jenkins.repo -O /etc/yum.repos.d/jenkins.repo [root\\@lewis63 yum.repos.d]# rpm --import http://pkg.jenkins.io/redhat/jenkins.io.key [root\\@lewis63 yum.repos.d]# yum install -y jenkins #默认安装最新版本。或者直接安装jenkins-2.93-1.1.noarch.rpm包 注：新版GitLab的服务端口为8080，为了不和GitLab的服务端口相冲突，修改Jenkins的默认端口8080为198 [root\\@lewis63 ~]# vim /etc/sysconfig/jenkins 改：56 JENKINS_PORT=\"8080\" 为：56 JENKINS_PORT=\"1198\" 10 JENKINS_HOME=\"/var/lib/jenkins\" #数据目录，建议用固态磁盘来存数据，可以自己定义 [root\\@lewis63 ~]# /etc/init.d/jenkins start 报错1： systemctl status jenkins.service Starting Jenkins bash: /usr/bin/java: No such file or directory 发现是找不到jdk，修改文件 解决： ln -s /usr/local/jdk/bin/java /usr/bin/java #做链接 报错2： 启动jenkins发现端口没有起来，查看jenkins日志 tail /var/log/jenkins/jenkins.log 权限不够 jenkins默认是以jenkins用户运行，修改jenkins用户为root [root\\@lewis63 ~]# vim /etc/sysconfig/jenkins JENKINS_USER=\"root\" 重新启动： [root\\@lewis63 ~]# /etc/init.d/jenkins start [root\\@lewis63 bin]# netstat -anput | grep 1198 tcp6 0 0 :::1198 :::* LISTEN 24112/java [root\\@lewis63 ~]# chkconfig jenkins on 浏览器访问http://192.168.1.63:1198 安装推荐的插件 3.手动安装jenkins插件 如果在下线安装插件失败了，或是无网环境下想安装插件，可以选择手动安装 安装成功后，登录系统，选择： 系统管理->插件管理->高级 插件下载地址： http://updates.jenkins-ci.org/download/plugins/ #在有网的环境下，把自己需要的插件下载好，然后再从本地上传。 方法2： 也可以直接把一台安装好jenkins插件服务器的/var/lib/jenkins/plugins目录下的文件复制到新的jenkins中。 把准备好的插件解压一下： [root\\@lewis63 jenkins]# tar czvf plugins.tar.gz plugins/ #cd /var/lib/jenkins/ #rm -rf /var/lib/jenkins/plugins #tar -zxvf plugins.tar.gz #上传plugins.tar.gz到linux系统上，解压缩 #chown jenkins.jenkins ./* -R #/etc/init.d/jenkins start 注：记得重启jenkins，这个非常重要，因为不重启，插件不会生效 到此jenkins安装成功。 登录gitlab http://192.168.1.63/ 用户名： root 登录jenkins http://192.168.1.63:198/ 用户名： admin Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-18 13:32:08 "},"python/example1.html":{"url":"python/example1.html","title":"第一节","keywords":"","body":"第一节 Copyright ©lewis 2018 all right reserved，powered by Gitbook该文件修订时间： 2018-09-18 17:22:22 "}}